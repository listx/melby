# Copyright 2023 Linus Arver
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#+title: Model
#+PROPERTY: header-args :noweb no-export

* Standard Resource Server

This section describes the implementation of the Standard Resource Server, a
generic =GenServer= that is designed to store arbitrary state from the output of
shell commands, all configured via Lua by the user. SRS is designed to be
generic enough to solve 80% of the problem of defining easily-tracked resources
which can be cached (stored in =GenServer= state) and retrieved for consumption,
typically for building shell prompts and/or status information.

The use of the cache is important because SRS will only execute the shell
command(s) needed to generate a new state if it detects possible staleness of
the existing data. Then, the new state (only if it is meaningfully different
than the existing one) will be used to compare against the previously-stored
statel. Then a diffing function will run to compare these states, and store a
new message in the message inbox for this SRS if there is some interesting
difference worth noting.

In summary (FIXME: add diagram), we store 2 things:

1. the history of states (has at least the 2 most recent "readings"), and
2. a message box to store notable changes to the state history.

We keep track of a standard resource, where the state for this resource is
generated via shell commands and parsed via Lua configuration. This is a
general-purpose module designed for use with various shell commands.

If no clients request information from us for some TTL period of time, we shut
down this process.

** Proto

#+name: melbyproto_melby_daemon
#+begin_src protobuf :tangle melby_daemon.proto
syntax = "proto3";

package melby_daemon;

message StandardResource {
  StandardResourceStatus status = 1;
  map<string, string> kvs = 2;
}

enum StandardResourceStatus {
  STANDARD_RESOURCE_STATUS_UNSPECIFIED = 0;

  // Denotes that the basic resource was not able to be retrieved because it was
  // invoked wrongly (e.g., a non-git-repo given to a git command).
  STANDARD_RESOURCE_STATUS_NOT_APPLICABLE = 1;

  STANDARD_RESOURCE_STATUS_LOADING = 2;
  STANDARD_RESOURCE_STATUS_LOADED = 3;
}
#+end_src

** Implementation

#+begin_src elixir :tangle daemon/lib/melbyd/standard_resource.ex
defmodule Melbyd.StandardResource do
  # If a Standard Resource Service process dies, don't restart it, because it
  # will be restarted on the next use (when a client requests info for it).
  use GenServer, restart: :temporary
  require Logger

  # 1 second. This is how quickly we can call the various reader functions
  # (which can be expensive). If we detect some possibility of staleness, we
  # re-execute the reader functions to retrieve the new state. If no staleness
  # is detected, then nothing happens in this tick.
  #
  # In the case where staleness is detected, we run the "read" function which
  # re-reads state. After this function complete, we run tick() again. So the
  # "busiest" we can be is tick() -> read() -> tick() -> read(), and so on. Or,
  # more realistically, it will be tick() -> tick() -> tick() -> read() ->
  # tick(), where there are multiple (possibly tens or hundreds) of ticks before
  # we need to call read().
  @tick_interval 1000

  # This function is called to initiate a brand new process. The most important
  # part here is the id, which is passed into via_tuple/1 to generate a tuple
  # that can be used to look up this process in a globally unique way. This way
  # we can send messages to *existing* processes and work with them.

  # Note that we pass the args_for_init tuple as the second argument to
  # GenServer.start_link/3, which in turn runs the init/1 callback by passing in
  # this same second argument.

  # An SRS instance is started by a gRPC call from melbyc, because only melbyc
  # knows which repo_id path to use (using "git"-flavored SRS as an example).
  # Because melbyc is the entrypoint, we should store all Lua config for SRS in
  # the same config used by the user for prompt generation and widget rendering.
  def start_link(
        %{
          id: {_resource_type, _resource_id} = id,
          resource: _resource,
          resource_opts: _resource_opts,
          ttl: _ttl,
          notify_on_exit_pid: _notify_on_exit_pid
        } = args_for_init
      ) do
    GenServer.start_link(__MODULE__, args_for_init, name: via_tuple(id))
  end

  # Used to identify this process uniquely in the entire Elixir system. We use
  # the gproc library for this.
  defp via_tuple(id) do
    key = {:n, :l, {__MODULE__, id}}
    {:via, :gproc, key}
  end

  @impl true
  def init(
        %{
          id: id,
          resource: resource,
          resource_opts: resource_opts,
          ttl: ttl,
          notify_on_exit_pid: notify_on_exit_pid
        } = _args
      ) do
    # Trap exits so that we can terminate gracefully (such as not logging an
    # error due to an intentional shutdown).
    #
    # Note that this will result in receiving all exits from all other linked
    # processes --- in our case this happens rather frequently from our use of
    # System.cmd/3 when the shell processes we start exit normally after
    # finishing execution (with a ":normal" reason).
    Process.flag(:trap_exit, true)

    Logger.info("Starting SRS #{inspect(id)}; ttl=#{inspect(ttl)}")

    # We have to subscribe to the fake_* topic ASAP (in init/1 here, not in
    # handle_continue/2), because it may be the case that handle_continue/2 will
    # not finish running by the time we broadcast the message to shut down this
    # GenServer on this fake_* topic.
    if resource_opts["fake"] do
      Logger.debug("#{inspect(id)}: subscribing to fake_" <> resource_opts["vm_fingerprint"])
      # Listen to the topic dedicated for all fakes created for a particular
      # vm_fingerprint. Then later when we're done with using this fake
      # (validation phase is over), we can delete all fakes by sending a message
      # here.
      Phoenix.PubSub.subscribe(Melbyd.PubSub, "fake_" <> resource_opts["vm_fingerprint"])
    end

    initial_state = %{
      id: id,
      resource: resource,
      resource_opts: resource_opts,
      state_hist: [],
      # This is stale because we haven't read any information yet.
      stale: true,
      ttl: ttl,
      ttl_max: ttl,
      notify_on_exit_pid: notify_on_exit_pid,
      reads: 0
    }

    # Return quickly, so that we don't block the creation of this GenServer. We
    # handle additional setup in the handle_continue/2 below.
    {:ok, initial_state, {:continue, :initial_read}}
  end

  @impl true
  def handle_continue(
        :initial_read,
        %{
          id: id,
          resource: resource,
          resource_opts: resource_opts,
          ttl: ttl,
          ttl_max: ttl,
          notify_on_exit_pid: notify_on_exit_pid,
          reads: reads
        } = state
      ) do
    {resource_type, resource_id} = id

    # Do an initial read to populate state. Note that this assumes that melbyd is
    # running on the same machine as the client.
    t1 = Timex.local()
    state_current = run_readers(resource, resource_opts, reads)
    t2 = Timex.local()

    # Give diagnostic report about how long it took to run all the commands to
    # generate the initial state.
    seconds_float = DateTime.diff(t2, t1, 10) / 10

    message = %{
      topic: "srs_#{resource_type}",
      from: "#{resource_id}",
      payload: %{
        level: "info",
        time: Calendar.strftime(t2, "%H:%M:%S"),
        text: "Initial read took #{seconds_float}s."
      }
    }

    Phoenix.PubSub.broadcast(Melbyd.PubSub, "srs_" <> resource_type, message)

    # History of states to store. This could be 1 or 100, depending on how much
    # recency data we want to retain. It may be that we want to store 100
    # (unique) states because we want to keep short-term-memory that we want to
    # retrieve, such as "what are the names of all git branches I have checked
    # out in the current session?" to be able to switch to them easily without
    # having to remember the exact names. Another example is providing users a
    # list of all unique SHAs that were visited in the current session.
    state_hist = [state_current]

    new_state = %{
      state
      | state_hist: state_hist,
        stale: false,
        reads: reads + 1
    }

    # Activate staleness detectors. For the FileSystem, we set up an
    # fs_event_handler.
    #
    # For fake resources, we skip setting up filesystem-based staleness
    # detection because we want to stop SRS from reading state on its own
    # initiative. Instead for fake resources, their states should only be
    # refreshed when the caller calls read().
    new_state =
      if resource_opts["fake"] do
        # For "fake" resources, skip filesystem flaggers because we could be
        # working with fake filesystem folders that don't actually exist. In
        # exchange, it's up to the rest of the fake handling code to understand
        # how to make up for this (make the user send in fake filesystem events
        # that SRS can still react to).
        new_state
      else
        # FIXME: Move all of this to a "setup_staleness_flaggers" function.
        [staleness_flaggers_luerl_array] = resource["staleness_flaggers"].([resource_id])

        staleness_flaggers_luerl_tables =
          Melbyd.LuerlUtil.array_to_native_list(staleness_flaggers_luerl_array)

        staleness_flaggers =
          staleness_flaggers_luerl_tables |> Enum.map(&Melbyd.LuerlUtil.table_to_native_map/1)

        Enum.reduce(staleness_flaggers, new_state, &setup_staleness_flagger/2)
      end

    # Start up the tick process to detect staleness and subsequent re-reading of
    # state. Only do this if we are a real resource.
    if not resource_opts["fake"] do
      tick(ttl, notify_on_exit_pid)
    end

    {:noreply, new_state}
  end

  defp run_readers(resource, resource_opts, reads) do
    [readers_luerl_array] = resource["readers"].([resource_opts])
    readers = Melbyd.LuerlUtil.array_to_native_list(readers_luerl_array)

    kvs =
      if resource_opts["fake"] do
        # Run the fake readers instead of the real ones.

        # For the time_idx, we can use a new "reads" field in the state that
        # starts at 0 and is incremented by 1 every time that run_readers()
        # completes. We don't care about overflows because Elixir uses arbitrary
        # precision integers (and btw it'll take billions of years of continuous
        # incrementation until we need to use more than 64 bits so even if
        # Elixir did not use arbitrary precision, we would virtually never
        # overflow).

        time_idx = reads

        # The fake readers generate data. We still need the regular readers
        # because we need to know which readers need which parsers.
        [fake_readers_luerl_table] = resource["fake"]["readers"].([resource_opts, time_idx])
        fake_readers = Melbyd.LuerlUtil.table_to_native_map(fake_readers_luerl_table)
        case read_fakes(readers, resource, resource_opts, fake_readers, time_idx) do
          {[], kvs} ->
            kvs

          {errors, _kvs} ->
            Logger.warning("got #{Kernel.length(errors)} errors reading fake readers")
            errors |> Enum.map(fn e -> Logger.warning(e) end)
            # Still return those kvs that were successfully parsed as expected.
            # FIXME: Or should we not crash here?
            raise "failed validation"
        end
      else
        # FIXME: Optionally run the readers concurrently for cases where we do
        # want the concurrency (e.g., we're hitting N different IP targets over
        # the network). E.g., for kubernetes contexts, most likely we should run
        # them all in parallel because they are talking to different clusters
        # with different IPs.
        #
        # We should by default read serially because it is "safer". E.g., for
        # git we definitely do not want to run everything in parallel because
        # each git command could block on a global lockfile located in the .git
        # folder of a repo.
        if resource_opts["read_parallel"] do
          read_parallel(readers, resource)
        else
          read_serial(readers, resource)
        end
      end

    %MelbyDaemon.StandardResource{status: :STANDARD_RESOURCE_STATUS_LOADED, kvs: kvs}
  end

  # For fake readers, check that the parser's output matches the expected output
  # in the fake.
  defp read_fakes(readers, resource, resource_opts, fake_readers, time_idx) do
    Enum.reduce(readers, {[], %{}}, fn reader_table, {errors, kvs} ->
      reader = Melbyd.LuerlUtil.table_to_native_map(reader_table)
      fake_reader_table = fake_readers[reader["parser"]]
      fake_reader = Melbyd.LuerlUtil.table_to_native_map(fake_reader_table)
      parser_func = resource["parser"][reader["parser"]]
      src = fake_reader["input"]
      kvs_subset = parser_func.([src]) |> Kernel.hd() |> Melbyd.LuerlUtil.table_to_native_map()

      # If the output does not match what we actually parsed, raise an error.
      expected = fake_reader["output"] |> Melbyd.LuerlUtil.table_to_native_map()

      errors = if kvs_subset != expected do
        # FIXME: Maybe use a map diffing library, like
        # https://hexdocs.pm/map_diff/MapDiff.html to get a shorter "diff" of
        # any key/value differences.
        ["resource type #{resource["type"]}: " <>
          "resource_opts #{inspect(resource_opts)}: " <>
          "time_idx #{time_idx}: " <>
          "expected #{inspect(expected)}, got #{inspect(kvs_subset)}" | errors]
      else
        errors
      end

      # Merge the data we've collected into acc.
      {errors, Map.merge(kvs, kvs_subset)}
    end)
  end

  defp read_single(reader_table, resource) do
    reader = Melbyd.LuerlUtil.table_to_native_map(reader_table)
    invocation = Melbyd.LuerlUtil.array_to_native_list(reader["invocation"])
    cmd_head = Kernel.hd(invocation)
    cmd_args = Enum.drop(invocation, 1)
    cd = reader["cd"]

    cmd_opts_cd =
      if cd != nil do
        [cd: cd]
      else
        []
      end

    cmd_opts_env =
      if reader["env"] != nil do
        env =
          Melbyd.LuerlUtil.table_to_native_map(reader["env"])
          |> Enum.map(fn {k, v} -> {k, v} end)

        [env: env]
      else
        []
      end

    cmd_opts = cmd_opts_cd ++ cmd_opts_env

    parser_func_name = reader["parser"]
    parser_func = resource["parser"][parser_func_name]

    src =
      try do
        case System.cmd(cmd_head, cmd_args, cmd_opts) do
          {stdout, 0} ->
            stdout

          {_stdout, error_code} ->
            Logger.warning("Command #{inspect(invocation)} failed with error code #{error_code}")

            # Return empty string. Parsers should know how to deal with the
            # empty string (and accept that no output means that we should
            # return a default value).
            ""
        end
      rescue
        e ->
          Logger.warning("Command #{inspect(invocation)} failed: #{Exception.message(e)}")
          ""
      end

    Logger.debug("Running parser_func #{inspect(parser_func_name)}")

    # Now parse the output with the custom function to generate some keys and
    # values (a map). For simplicity both the keys and values here should not be
    # a collection type (map, array, etc) and instead be a primitive like a
    # string or number.
    parser_func.([src]) |> Kernel.hd() |> Melbyd.LuerlUtil.table_to_native_map()
  end

  defp read_serial(readers, resource) do
    Enum.reduce(readers, %{}, fn reader_table, acc ->
      kvs_subset = read_single(reader_table, resource)
      # Merge the data we've collected into acc.
      Map.merge(acc, kvs_subset)
    end)
  end

  # async tasks can crash the caller (and vice versa)
  # https://hexdocs.pm/elixir/1.14.2/Task.html#module-async-and-await. Also,
  # note that this function may take minutes, or even hours, to return. But it's
  # OK because we're not blocking anyone else.
  defp read_parallel(readers, resource) do
    tasks =
      Enum.reduce(readers, [], fn reader_table, acc ->
        task = Task.async(fn -> read_single(reader_table, resource) end)
        # Collect this task.
        [task | acc]
      end)

    # Each task returns a map. We need to merge all of these maps into each
    # other.
    maps = Task.await_many(tasks, :infinity)
    Enum.reduce(maps, &Map.merge/2)
  end

  # FIXME: put this inside the callbacks section for handle_call.
  @impl true
  def handle_call(
        :read,
        _from,
        %{state_hist: state_hist, ttl: ttl, ttl_max: ttl_max} = state
      ) do
    response =
      case state_hist do
        [] -> %MelbyDaemon.StandardResource{status: :STANDARD_RESOURCE_STATUS_LOADING}
        [current | _] -> current
      end

    # If ttl is < 1, then this means that either the ttl naturally expired (ttl
    # == 0) or that we set this ttl manually to -1 because the fs watcher died.
    # In either case, do not change the ttl.
    #
    # Otherwise, reset the ttl because a client actually needed this
    # information.
    ttl_new =
      if ttl < 1 do
        ttl
      else
        ttl_max
      end

    {
      :reply,
      # Response to the caller.
      response,
      # New state of this GenServer.
      %{state | ttl: ttl_new}
    }
  end

  # GenServer callbacks.
  __NREF__melbyd_srs_handle_call
  __NREF__melbyd_srs_handle_cast
  __NREF__melbyd_srs_handle_info

  # Tick
  __NREF__melbyd_srs_tick

  # Mark staleness
  __NREF__melbyd_srs_staleness
  __NREF__melbyd_srs_staleness_detector_setup
  # Filesystem-based staleness
  __NREF__melbyd_srs_staleness_filesystem_boilerplate
  __NREF__melbyd_srs_staleness_filesystem_helpers

  # Client interface
  __NREF__melbyd_srs_client_interface
end

# Supervisor.
__NREF__melbyd_srs_supervisor
#+end_src

** Tick

#+header: :noweb-ref __NREF__melbyd_srs_tick
#+begin_src elixir
# Send a "tick" message to our GenServer in 1 second. See
# https://stackoverflow.com/a/32097971/437583.
defp tick(ttl, notify_on_exit_pid) do
  case ttl do
    n when n in -1..0 ->
      if n == 0 do
        Logger.info("TTL expired; shutting down this GenServer due to client neglect")
      else
        Logger.info(
          "TTL expired manually; shutting down this GenServer"
        )
      end

      # Used for testing, where we assert that we can receive this
      # ":shutting_down" message after the ttl expires.
      if notify_on_exit_pid do
        send(notify_on_exit_pid, :shutting_down)
      end

      Process.exit(self(), :ttl_deadline_exceeded)
    _ ->
      # Send after 1 second. We could alternatively use :timer.send_interval
      # (Erlang function) in init/1 and avoid calling this function manually in
      # handle_info/2, but then that would send the tick at a constant rate,
      # regardless of how long it takes to process the tick. This runs the risk of
      # growing the message queue at a faster rate than it can be processed
      # (unbounded growth).
      Process.send_after(self(), :tick, @tick_interval)
  end
end
#+end_src

#+header: :noweb-ref __NREF__melbyd_srs_handle_info
#+begin_src elixir
# Process tick. The tick must handle the true and false cases for the "stale"
# key of the state. First we handle the case where stale is true (we must
# re-read data).
__NREF__melbyd_srs_tick_do_work

@impl true
def handle_info(
      :tick,
      %{ttl: ttl, notify_on_exit_pid: notify_on_exit_pid} = state
    ) do
  new_state = maybe_refresh_state_and_notify(state)

  # Continue ticking for the future. But optionally die if ttl is too low.
  tick(ttl, notify_on_exit_pid)

  {:noreply, new_state}
end
#+end_src

#+name: __NREF__melbyd_srs_tick_do_work
#+begin_src elixir
defp maybe_refresh_state_and_notify(
       %{
         id: id,
         resource: resource,
         resource_opts: resource_opts,
         state_hist: state_hist,
         stale: stale,
         ttl: ttl,
         reads: reads
       } = state
     ) do
  if stale do
    Logger.info("Re-reading state for #{inspect(id)}")
    new = run_readers(resource, resource_opts, reads)
    Logger.info("Finished re-reading state for #{inspect(id)}")

    new_state_hist =
      case state_hist do
        # This list is always populated with at least 1 element because we
        # populate it as a singleton list in init/1.
        [old | _] ->
          if old == new do
            # NOP because there is no change between the currnt reading and the
            # last reading we did.
            Logger.info("skipping addition of new state; NOP")
            state_hist
          else
            # Generate any new messages for any diff between the old and new
            # states.
            Logger.info("checking for any new messages to broadcast")
            {_, resource_id} = id
            resource["notify"].([resource_id, old, new])

            # Drop oldest state from state_hist if adding (prepending) to it
            # would exceed our history size.
            [new | state_hist] |> Enum.take(resource["history_size"])
          end
      end

    %{state | state_hist: new_state_hist,
              stale: false,
              ttl: ttl - 1,
              reads: reads + 1}
  else
    # Now handle the case where staleness is false (no need to read new data).
    # In this case the only thing that happens is the ttl age getting older (1
    # unit closer to 0).

    %{state | ttl: ttl - 1}
  end
end
#+end_src

#+header: :noweb-ref __NREF__melbyd_srs_handle_call
#+begin_src elixir
@impl true
def handle_call(
      :tick,
      _from,
      state
    ) do
  new_state = maybe_refresh_state_and_notify(state)

  # Unlike for the handle_info version, we do not tick again on our own, because
  # this is meant to be used only as a way for fake resources to get updated
  # manually in a synchronized fashion. If we were to tick ourselves now, then
  # we would essentially start updating our state asynchronously, missing the
  # point.
  {:reply, :ok, new_state}
end
#+end_src

** Marking staleness

If we mark an SRS GenServer as stale, this forces the re-reading of state such
that it is loaded as the newest element in the =state_hist= queue.

#+name: __NREF__melbyd_srs_staleness
#+begin_src elixir
defp mark_stale(id) do
  GenServer.cast(via_tuple(id), :mark_stale)
end
#+end_src

For production, we don't care about being synchronous. We also can't use
=self()= because we might have to mark other GenServer SRS's as stale (e.g., for
filesystem-based staleness flaggers that walk up the filesystem tree and mark
everyone there as stale).

In our GenServer callback =handle_cast(:mark_stale, ...)= below, we also set
=status= of the current (head) element in =state_hist= to
=:STANDARD_RESOURCE_STATUS_LOADING=. This is so that any client reads of our
state between now and the next tick() will know that we've recognized the need
to refresh the state on the next tick().

#+name: __NREF__melbyd_srs_handle_cast
#+begin_src elixir
@impl true
def handle_cast(:mark_stale, %{stale: _, state_hist: [current | rest]} = state) do
  {:noreply,
   %{
     state
     | stale: true,
       state_hist: [%{current | status: :STANDARD_RESOURCE_STATUS_LOADING} | rest]
   }}
end
#+end_src

For fake resources, we want to make this function block with a =call= so that we
can be more precise with how its state is updated with a followup coordinated
=:tick= message (also a =call=).

#+header: :noweb-ref __NREF__melbyd_srs_handle_call
#+begin_src elixir
@impl true
def handle_call(:mark_stale, _from, %{stale: _, state_hist: [current | rest]} = state) do
  {:reply,
   :ok,
   %{
     state
     | stale: true,
       state_hist: [%{current | status: :STANDARD_RESOURCE_STATUS_LOADING} | rest]
   }}
end
#+end_src

*** Filesystem-based staleness

We want to be able to automatically mark for staleness based on filesystem
events. This is the reason for this section. Note that this notion of
filesystem-based staleness is completely optional --- if an SRS GenServer is
configured so that it doesn't "register" for filesystem-based staleness, none of
the code here will get used (because no one will send the ={:file_event, ...}=
tuple to us).

Regarding implementation, the key here is to forward filesystem events (detected
as ={path, events}= tuples) to the Lua function that the user defines. It's up
to that function to return a True or False boolean. If it returns True, then we
mark the current SRS GenServer as *stale*, as well as all parent SRS GenServers
as stale (if any), by calling =mark_all_stale_from/1=.

The original reason why we mark all parents as stale is for the case where we
have Git submodules and we delete/edit some files in the submodule. In this
scenario it could be that the superproject Git repo needs to update its
information, and so we need to mark it as stale as well. And because submodules
can technically be nested, we need to go all the way up to the filesystem root.

Conceivably, other SRS GenServers that rely on filesystem staleness probably
want the same =mark_all_stale_from/1= behavior.

#+header: :noweb-ref __NREF__melbyd_srs_handle_info
#+begin_src elixir
@impl true
def handle_info(
      {:file_event, _watcher_pid, {path, events}},
      %{
        id: id,
        fs_event_handler: fs_event_handler,
        stale: false
      } = state
    ) do
  {resource_type, _resource_id} = id
  # Now translate our path and events arguments to send into the Lua function,
  # and call it.
  [should_mark_stale] = fs_event_handler.([path, events])

  if should_mark_stale do
    # Invalidate the cache entry for all current and parent SRS GenServers
    # between / and path. This includes us (our particular SRS GenServer
    # instance) as well.
    mark_all_paths_stale_from({resource_type, path})
  else
    Logger.debug(
      "ignoring Git index path #{path}; events:#{inspect(events)}"
    )
  end

  {:noreply, state}
end
#+end_src

**** Boilerplate (FIXME: rename this heading and avoid "boilerplate" because it means nothing)

This section captures universally-applicable filesystem events which are
independent of what the user specifies in their Lua configuration.

First, if the filesystem watcher dies, we set the time-to-live (TTL) value for
our GenServer to -1 so that it will exit itself on the next tick. Setting this
to -1 is important because it signals to the other =handle_call= callback which
accepts the =:read= atom that it should not reset the TTL back up to =ttl_max=.

#+header: :noweb-ref __NREF__melbyd_srs_handle_info
#+begin_src elixir
@impl true
def handle_info(
      {:file_event, watcher_pid, :stop},
      %{
        id: id
      } = state
    ) do
  Logger.info("SRS id #{inspect(id)}, fs watcher #{inspect(watcher_pid)}: FileSystem monitor stopped")

  # FIXME: Use {:stop, reason, new_state} here to stop the process instead of
  # (ab)using ttl. See pages 174-175 of Elixir In Action.
  {:noreply, %{state | ttl: -1}}
end
#+end_src

The second is to ignore all filesystem events if the GenServer state has already
been marked as *stale*. This is because the only thing that a filesystem event
can do is to flag for staleness; if we're already stale, then any additional
filesystem event is redundant as far as staleness is concerned. On the next
tick, when we see that we're in a stale state, we will regenerate the state and
mark ourselves as being fresh (=stale: false=) again.

#+header: :noweb-ref __NREF__melbyd_srs_handle_info
#+begin_src elixir
@impl true
def handle_info(
      {:file_event, _watcher_pid, {_path, _events}},
      %{
        stale: true
      } = state
    ) do
  Logger.debug("Ignoring filesystem event because state is already stale")
  {:noreply, state}
end
#+end_src

***** Setup

Setting up a filesystem-based staleness detector requires calling out to the
=FileSystem= library, so that we can subscribe to filesystem events in the first
place. We do this if we see that the resource has a configuration specified for
it.

When the user specifies a directory to watch, we watch it and all of it
subdirectories for changes.

#+header: :noweb-ref __NREF__melbyd_srs_staleness_detector_setup
#+begin_src elixir
defp setup_staleness_flagger(
       %{"type" => "filesystem",
         "watch_paths" => watch_paths_lua_array,
         "fs_event_handler" => fs_event_handler} =
         _staleness_flagger,
       initial_state
     ) do

  watch_paths = Melbyd.LuerlUtil.array_to_native_list(watch_paths_lua_array)
  Logger.info("Watching filesystem directory #{inspect(watch_paths)}")
  {:ok, watcher_pid} = FileSystem.start_link(dirs: watch_paths)
  FileSystem.subscribe(watcher_pid)

  # We need to save this info about fs, because we need to run the fs event
  # handler (we can do the full lookup using get_resources but this is slightly
  # cheaper).
  Map.put(initial_state, :fs_event_handler, fs_event_handler)
end
#+end_src

**** Helpers

Here are some helper functions. The main workhorse here is
=mark_all_stale_from/1=, which marks all SRS GenServers from the given path to
the root directory (=/=) as stale.

#+header: :noweb-ref __NREF__melbyd_srs_staleness_filesystem_helpers
#+begin_src elixir
# Mark the given path as stale, as well as all other SRS GenServers whose id's
# are of the form "{resource_type, path}" where "path" is a parent path.
defp mark_all_paths_stale_from({resource_type, path}) do
  get_all_parents(path)
  |> Enum.map(fn p -> mark_stale({resource_type, p}) end)
end

# Given "/a/b/c", return ["/", "/a", "/a/b", "/a/b/c"]
defp get_all_parents(path) do
  parts = Path.split(path)
  parts_len = length(parts)

  1..parts_len
  |> Enum.map(&(Enum.take(parts, &1) |> Path.join()))
end
#+end_src

*** Duration-based staleness (polling)

Some resources should be re-read every few seconds or so. One example is
whenever we want to scrape information from another service, which may or may
not have changed state. For these things, we can use a duration-based staleness
flagger. It is very simple --- whenever some duration of time has passed, we
mark the resource as stale, and repeat agan after the same duration, forever.
This is also known as polling. One common, basic example in the Kubernetes world
is when users invoke =watch kubectl get ...= to poll Kubernetes state every 2
seconds.

Compared to filesystem-based staleness, duration-based staleness does not
require an event handling function (to detect whether to accept or reject the
event) to be implemented in Lua. This is becausee an elapsed duration of time is
a universal truth (for all intents and purposes) and does not require additional
checking.

See https://elixirforum.com/t/multiple-intervals-for-genserver/6026 for a
discussion about timers and durations. There they mention
https://hex.pm/packages/quantum which is basically cron but for Elixir.

#+header: :noweb-ref __NREF__melbyd_srs_handle_info
#+begin_src elixir
@impl true
def handle_info(
      :duration_event,
      %{
        id: id,
        stale: false
      } = state
    ) do
  {resource_type, _resource_id} = id
  mark_stale({resource_type, id})

  {:noreply, state}
end
#+end_src

Similar to filesystem-based staleness, we ignore the =:duration_event= if our
state has already been marked stale (because it is redundant).

#+header: :noweb-ref __NREF__melbyd_srs_handle_info
#+begin_src elixir
@impl true
def handle_info(
      :duration_event,
      %{
        stale: true
      } = state
    ) do
  Logger.debug("Ignoring duration event because state is already stale")
  {:noreply, state}
end
#+end_src

Finally, we need to set up a timer to generate these =:duration_event= atoms to
send them to our SRS GenServer. Thankfully, Erlang ships with a =:timer= module
which has everything we need. The duration must be set using ISO 8601 notation,
and is only precise to 1 whole second (sub-second durations are ignored).

#+header: :noweb-ref __NREF__melbyd_srs_staleness_detector_setup
#+begin_src elixir
defp setup_staleness_flagger(
       %{"type" => "duration", "duration" => duration} = _staleness_flagger,
       initial_state
     ) do
  Logger.info("Setting up duration-based staleness flagger, with duration #{duration}")
  :timer.send_interval(:timer.seconds(duration_to_seconds(duration)), self(), :duration_event)

  Map.put(initial_state, :duration, duration)
end

defp duration_to_seconds(s) do
  case Elixir.Timex.Parse.Duration.Parsers.ISO8601Parser.parse(s) do
    {:ok, d} ->
      seconds = Timex.Duration.to_seconds(d, truncate: true)

      if seconds == 0 do
        Logger.warning("duration #{s} was parsed as 0 seconds; using 2 seconds as fallback")
        2
      else
        seconds
      end

    {:error, err} ->
      Logger.warning("failed to parse duration #{s}: #{inspect(err)}; using 2 seconds as fallback")
      2
  end
end
#+end_src

** Graceful shutdown

#+header: :noweb-ref __NREF__melbyd_srs_handle_info
#+begin_src elixir
@impl true
def handle_info(
      {:EXIT, from_pid, reason},
      %{
        id: id
      } = state
    ) do
  Logger.debug("SRS #{inspect(id)}: Got exit reason #{inspect(reason)} from pid #{inspect(from_pid)}")
  case reason do
    :normal ->
      # This can happen if, e.g., a System.cmd/3 finishes running successfully.
      {:noreply, state}
      # This is when we are asked to shut down immediately (e.g., for a fake SRS
      # that is no longer needed).
    :release_fake_resource ->
      {:stop, :normal, state}
    :ttl_deadline_exceeded ->
      # Invoke our terminate/2 callback by returning with the ":stop" atom.
      {:stop, :normal, state}
    _ ->
      {:stop, reason, state}
  end
end

@impl true
def terminate(
      reason,
      %{
        id: id
      } = _state
    ) do
  Logger.info("SRS #{inspect(id)}: Got exit reason #{inspect(reason)}; shutting down")
end
#+end_src

** Client interface

The client interface is rather simple: there is just =read/2= which either
retrieves the current state from the SRS GenServer, or creates a new one if it
doesn't exist and returns an empty state. Note that =read/2= itself has no idea
how to actually generate the state from scratch --- instead it can only read
whatever is already in the GenServer's state (if any). The job of actually
generating the state from scratch, based on the Lua configuration, is left to
the =run_readers/2= private method.

#+name: __NREF__melbyd_srs_client_interface
#+begin_src elixir
def read(resource, resource_opts) do
  # At this point we have all the information we need in order to instantiate a
  # new SRS GenServer. We need to start it up (if necessary) and get information
  # out of it. This optional startup can be handled by the DynamicSupervisor,
  # which can do a call into gproc (process registry) to determine if the
  # GenServer of the type and options exists.

  resource_id =
    cond do
      resource_opts["fake"] ->
        resource["fake"]["resource_id_func"].([resource_opts]) |> Kernel.hd()

      resource["resource_id_command"] != nil ->
        run_resource_id_command(resource, resource_opts)

      resource["resource_id_func"] != nil ->
        resource["resource_id_func"].([resource_opts]) |> Kernel.hd()

      true ->
        ""
    end

  if resource_id == "" do
    Logger.warning(
      "resource_id cannot be empty: failed to generate srs_id for resource " <>
        "#{inspect({resource, resource_opts})} --- if this is a fake, then " <>
        "it means that your resource_id_func could be returning an empty string"
    )

    %MelbyDaemon.StandardResource{status: :STANDARD_RESOURCE_STATUS_NOT_APPLICABLE}
  else
    # Warn users about misbehaving resource_ids for non-fake resources.
    if String.starts_with?(resource_id, "fake->") && !resource_opts["fake"] do
      Logger.warning(
        "resource_id starts with 'fake->' but 'fake' key is not set in"
          <> "resource_opts: #{inspect({resource, resource_opts})}"
      )

      %MelbyDaemon.StandardResource{status: :STANDARD_RESOURCE_STATUS_NOT_APPLICABLE}
    else
      # Prepend "fake->" to the resource_id so that it is in a different
      # "namespace" and does not clash with real resource ids. It could be the
      # case that the real resource's id command or function would also output a
      # leading "fake->" string, but this is very unlikely.
      resource_id =
        if resource_opts["fake"] do
          "fake->#{resource_id}"
        else
          resource_id
        end

      # We need to encode the resource type as well into the id because it may
      # be the case that other resource types also end up generating the same
      # id, such as when both resource types depend on the same filesystem
      # path.
      srs_id = {resource["type"], resource_id}

      case :gproc.lookup_pids({:n, :l, {Melbyd.StandardResource, srs_id}}) do
        [pid] ->
          # This StandardResource with the given id already exists.
          Logger.info("Found existing pid for #{inspect(srs_id)}: #{inspect(pid)}")

          # If it's a fake resource, we manually mark it stale first, then force
          # a read (with a tick).
          if resource_opts["fake"] do
            GenServer.call(pid, :mark_stale)
            GenServer.call(pid, :tick)
          end

          GenServer.call(pid, :read)

        _ ->
          # Start the StandardResource with the given id. This is idempotent and
          # will not spawn a new GenServer if one already exists with the given
          # id.
          #
          # Because we wrap the start_watcher() call inside a Task, it also runs
          # asynchronously (so that we don't block until the startup is finished
          # before returning the "LOADING" status below).
          Task.Supervisor.start_child(Melbyd.TaskSupervisor, fn ->
            Melbyd.StandardResourceSupervisor.start_srs(srs_id, resource, resource_opts)
          end)

          # We started the watcher just above asynchronously. For now return a
          # blank struct with the "LOADING" status so that the caller can know
          # that the given repo is indeed a Git repo but that we just don't have
          # any data yet.
          %MelbyDaemon.StandardResource{status: :STANDARD_RESOURCE_STATUS_LOADING}
      end
    end
  end
end

# Return a resource_id by running the given command. Also return the appropriate
# StandardResourceStatus atom.
def run_resource_id_command(resource, resource_opts) do
  # When we call a luerl-decoded function, we have to pass in arguments as a
  # list, as in [resource_opts] below.
  [resource_id_command_luerl_table] = resource["resource_id_command"].([resource_opts])
  resource_id_command = Melbyd.LuerlUtil.table_to_native_map(resource_id_command_luerl_table)
  invocation = resource_id_command["invocation"] |> Melbyd.LuerlUtil.array_to_native_list()
  cmd_head = Kernel.hd(invocation)
  cmd_args = Enum.drop(invocation, 1)
  cd = resource_id_command["cd"]

  cmd_opts =
    if cd != nil do
      [cd: cd]
    else
      []
    end

  # If the resource id command requirse some additional processing (the command
  # itself does not return a unique, simple string), we can construct our final
  # format with the help of the parser.
  parser_func_name = resource_id_command["parser"]
  parser_func = resource["parser"][parser_func_name] || (&Function.identity/1)

  case System.cmd(cmd_head, cmd_args, cmd_opts) do
    {stdout, 0} ->
      # For example, "git rev-parse ..." can output a trailing newline, which we
      # need to remove.
      stdout_trimmed = String.trim_trailing(stdout)
      resource_id = stdout_trimmed

      if resource_id == "" do
        Logger.warning(
          "command returned successfully, but had no output: failed to " <>
            "generate srs_id for resource #{inspect({resource, resource_opts})}"
        )
      end

      # If we have an associated parser function, use it to help construct the
      # final ID format. Otherwise (or if it errors out due to an invalid
      # input), just use the output we got from above.
      parsed_resource_id =
        if parser_func != nil do
          parser_func.([stdout_trimmed]) |> Kernel.hd()
        end

      resource_id =
        if parsed_resource_id != nil && String.trim(parsed_resource_id) != "" do
          parsed_resource_id
        end

      resource_id

    {_stdout, error_code} ->
      Logger.warning(
        "resource_id_command failed with error code #{error_code}: failed to " <>
          "generate srs_id for resource #{inspect({resource, resource_opts})}"
      )

      ""
  end
end
#+end_src

** Supervisor

Note that =Melbyd.StandardResource.read/4=, the standard client function, is the
one that reaches out to =Melbyd.StandardResourceSupervisor= to start the
=Melbyd.StandardResource= GenServer under a Supervisor. That is,
=Melbyd.StandardResource= knows how to supervise itself.

#+name: __NREF__melbyd_srs_supervisor
#+begin_src elixir
defmodule Melbyd.StandardResourceSupervisor do
  @moduledoc """
  StandardResource GenServers are created dynamically during runtime. This
  module supervises these servers so that they are restarted if they fail
  unexpectedly.
  """

  # This automatically defines child_spec/1
  use DynamicSupervisor

  require Logger

  def start_link(init_arg) do
    Logger.info("Starting SRS dynamic supervisor")
    DynamicSupervisor.start_link(__MODULE__, init_arg, name: __MODULE__)
  end

  @impl true
  def init(_init_arg) do
    DynamicSupervisor.init(strategy: :one_for_one)
  end

  def start_srs(srs_id, resource, resource_opts) do
    case start_child(srs_id, resource, resource_opts) do
      {:ok, pid} -> pid
      {:error, {:already_started, pid}} -> pid
      unknown -> Logger.warning("start_srs failed: #{inspect(unknown)}")
    end
  end

  defp start_child(srs_id, resource, resource_opts) do
    ttl = Application.get_env(:melbyd, :melbyd_srs_ttl)

    # We pass in the srs_id ({resource_type, resource_id}) and ttl as an
    # argument to the start_link/1 function of Melbyd.StandardResource.
    #
    # IOW, start_child() invokes the start_link() function of
    # Melbyd.StandardResource.
    DynamicSupervisor.start_child(
      __MODULE__,
      {Melbyd.StandardResource, %{id: srs_id,
                                 resource: resource,
                                 resource_opts: resource_opts,
                                 ttl: ttl,
                                 notify_on_exit_pid: nil}}
    )
  end
end
#+end_src

* Shell Process Service

The purpose of the Shell Process Service is to subscribe to various PubSub
topics. That is, this is the consumer and the SRS GenServers are the producers.

The idea is to let SRS GenServers publish messages to topics that they control
whenever anything interesting happens (where the determination of "interesting"
is up to the user's Lua configuration). And then it's up to SPS GenServers to
subscribe to these topics and display these messages to the user.

#+begin_src elixir :tangle daemon/lib/melbyd/shell_process.ex
defmodule Melbyd.ShellProcess do
  use GenServer, restart: :temporary
  require Logger

  @tick_interval 1000

  def start_link(
        %{
          shell_pid: shell_pid,
          topic_handlers: _topic_handlers,
          env_vars: _env_vars,
          ttl: _ttl,
          notify_on_exit_pid: _notify_on_exit_pid
        } = args_for_init
      ) do
    GenServer.start_link(__MODULE__, args_for_init, name: via_tuple(shell_pid))
  end

  defp via_tuple(shell_pid) do
    key = {:n, :l, {__MODULE__, shell_pid}}
    {:via, :gproc, key}
  end

  @impl true
  def init(
        %{
          shell_pid: shell_pid,
          topic_handlers: topic_handlers,
          env_vars: env_vars,
          ttl: ttl,
          notify_on_exit_pid: notify_on_exit_pid
        } = _args
      ) do
    Process.flag(:trap_exit, true)
    Logger.info("Starting SPS #{inspect(shell_pid)}; ttl=#{inspect(ttl)}")

    # Subscribe to topics.
    topics = Enum.map(topic_handlers, fn {topic, _handler} -> topic end)
    Enum.map(topics, fn topic -> Phoenix.PubSub.subscribe(Melbyd.PubSub, topic) end)
    Logger.info("Subscribed to these topics: #{inspect(topics)}")

    initial_state = %{
      shell_pid: shell_pid,
      messages: [],
      topic_handlers: topic_handlers,
      topics: topics,
      env_vars: env_vars,
      ttl: ttl,
      ttl_max: ttl,
      notify_on_exit_pid: notify_on_exit_pid
    }

    # Start up the tick process to detect TTL deadlines.
    tick(ttl, notify_on_exit_pid)

    {:ok, initial_state}
  end

  @impl true
  def handle_call(
        {:get_messages, topic_handlers},
        _from,
        %{shell_pid: shell_pid,
          messages: messages,
          topics: already_subscribed_topics, ttl_max: ttl_max} = state
      ) do

    # If there are topics of interest that have not yet been subscribed to,
    # subscribe to them as well. But also unsubscribe from topics that we don't
    # care about any more.
    #
    # FIXME: In practice, because our Lua config is essentially immutable, we
    # never unsubscribe from topics because the topics list never changes.
    topics = Enum.map(topic_handlers, fn {topic, _handler} -> topic end)
    topics_new = topics -- already_subscribed_topics
    Enum.map(topics_new, fn topic -> Phoenix.PubSub.subscribe(Melbyd.PubSub, topic) end)
    topics_obsolete = already_subscribed_topics -- topics
    Enum.map(topics_obsolete, fn topic -> Phoenix.PubSub.unsubscribe(Melbyd.PubSub, topic) end)

    if length(messages) > 0 do
      Logger.info("SPS #{shell_pid}: sending messages to client: #{inspect(messages)}")
    end

    {
      :reply,
      # Reverse the messages, because we store the newest one first.
      Enum.reverse(messages),
      # Erase messages buffer because we've just dumped it to the client.
      %{state | messages: [], ttl: ttl_max}
    }
  end

  @impl true
  def handle_call(
        {:update_env_vars, env_vars_new},
        _from,
        %{shell_pid: shell_pid, env_vars: env_vars_old} = state
      ) do

    if env_vars_new != env_vars_old do
      Logger.info("SPS #{shell_pid}: updating env_vars from #{inspect(env_vars_old)} " <>
        "to #{inspect(env_vars_new)}")
    end

    {
      :reply,
      nil,
      %{state | env_vars: env_vars_new}
    }
  end

  # GenServer callbacks.
  __NREF__melbyd_sps_handle_info

  # Tick
  __NREF__melbyd_sps_tick

  # Client interface
  __NREF__melbyd_sps_client_interface
end


__NREF__melbyd_sps_supervisor
#+end_src

** Tick

This is modeled after =Melbyd.StandardResource.tick/2=.

#+header: :noweb-ref __NREF__melbyd_sps_tick
#+begin_src elixir
# FIXME: This code is identical to the one in Melbyd.StandardResource.tick/2. Can
# we make it DRY somehow?
defp tick(ttl, notify_on_exit_pid) do
  case ttl do
    n when n in -1..0 ->
      if n == 0 do
        Logger.info("TTL expired; shutting down this GenServer due to client neglect")
      else
        Logger.info(
          "TTL expired manually; shutting down this GenServer"
        )
      end

      # Used for testing, where we assert that we can receive this
      # ":shutting_down" message after the ttl expires.
      if notify_on_exit_pid do
        send(notify_on_exit_pid, :shutting_down)
      end

      Process.exit(self(), :ttl_deadline_exceeded)
    _ ->
      Process.send_after(self(), :tick, @tick_interval)
  end
end
#+end_src

#+header: :noweb-ref __NREF__melbyd_sps_handle_info
#+begin_src elixir
@impl true
def handle_info(
      :tick,
      %{
        ttl: ttl,
        notify_on_exit_pid: notify_on_exit_pid
      } = state
    ) do
  # Continue ticking for the future. But optionally die if ttl is too low.
  tick(ttl, notify_on_exit_pid)
  {:noreply, %{state | ttl: ttl - 1}}
end
#+end_src

** Handle PubSub messages

We filter out messsages that don't apply to us. For example, if the message is
about a Git repo at =/a/b/c= where =c= is the repo root, but we (the shell
process) is currently located at =/a/b=, then we need to discard this message.

#+header: :noweb-ref __NREF__melbyd_sps_handle_info
#+begin_src elixir
@impl true
def handle_info(
      %{topic: topic, from: _from, payload: _payload} = message,
      %{
        shell_pid: shell_pid,
        messages: messages,
        topic_handlers: topic_handlers,
        env_vars: env_vars
      } = state
    ) do
  Logger.info("SPS #{shell_pid}: Handling PubSub message: #{inspect(message)}")

  keep_message =
    if Map.has_key?(topic_handlers, topic) do
      should_keep_message = topic_handlers[topic]
      should_keep_message.([message, env_vars]) |> Kernel.hd()
    else
      # If we can't find an associated filter function for this topic, discard it
      # but log a warning.
      Logger.warning("could not find filter function for PubSub message #{inspect(message)}")

      false
    end

  if keep_message do
    Logger.info("SPS #{shell_pid}: Keeping message #{inspect(message)}")
    {:noreply, %{state | messages: [message | messages]}}
  else
    Logger.info("SPS #{shell_pid}: Dropping message #{inspect(message)}")
    {:noreply, state}
  end
end
#+end_src

** Graceful shutdown

This is identical to the graceful shutdown logic for SRS.

FIXME: Can we make it DRY? Maybe use a macro, or some new utility functions? Or
a behaviour or protocol...?

#+header: :noweb-ref __NREF__melbyd_sps_handle_info
#+begin_src elixir
@impl true
def handle_info(
      {:EXIT, from_pid, reason},
      %{shell_pid: shell_pid} = state
    ) do
  Logger.debug("SPS #{shell_pid}: Got exit reason #{inspect(reason)} from pid #{inspect(from_pid)}; exiting")
  case reason do
    :normal ->
      # This can happen if, e.g., a System.cmd/3 finishes running successfully.
      {:noreply, state}
    :ttl_deadline_exceeded ->
      # Invoke our terminate/2 callback by returning with the ":stop" atom.
      {:stop, :normal, state}
    _ ->
      {:stop, reason, state}
  end
end

@impl true
def terminate(
      reason,
      %{shell_pid: shell_pid} = _state
    ) do
  Logger.info("SPS #{shell_pid}: Got exit reason #{inspect(reason)}; shutting down")
end
#+end_src

** Client interface

The =get_messages/2= function either retrieves all messages from this SPS
GenServer's =messages= field, or if there isn't a GenServer that has started
yet, just creates one.

The internals here mirror the design in =Melbyd.StandardResource.read/2=.

#+name: __NREF__melbyd_sps_client_interface
#+begin_src elixir
def get_messages(shell_pid, topic_handlers, env_vars) do
  case :gproc.lookup_pids({:n, :l, {Melbyd.ShellProcess, shell_pid}}) do
    [pid] ->
      Logger.info("Found existing pid for #{inspect(shell_pid)}: #{inspect(pid)}")
      # We update the env_vars in the GenServer state, because otherwise it will
      # always keep the same env_vars that it was created with.
      GenServer.call(pid, {:update_env_vars, env_vars})
      GenServer.call(pid, {:get_messages, topic_handlers})

    _ ->
      Task.Supervisor.start_child(Melbyd.TaskSupervisor, fn ->
        Melbyd.ShellProcessSupervisor.start_sps(shell_pid, topic_handlers, env_vars)
      end)

      # Return empty list (no messages) for now.
      []
  end
end
#+end_src

** Supervisor

#+name: __NREF__melbyd_sps_supervisor
#+begin_src elixir
defmodule Melbyd.ShellProcessSupervisor do
  use DynamicSupervisor

  require Logger

  def start_link(init_arg) do
    Logger.info("Starting SPS dynamic supervisor")
    DynamicSupervisor.start_link(__MODULE__, init_arg, name: __MODULE__)
  end

  @impl true
  def init(_init_arg) do
    DynamicSupervisor.init(strategy: :one_for_one)
  end

  def start_sps(shell_pid, topic_handlers, env_vars) do
    case start_child(shell_pid, topic_handlers, env_vars) do
      {:ok, pid} -> pid
      {:error, {:already_started, pid}} -> pid
      unknown -> Logger.warning("start_sps failed: #{inspect(unknown)}")
    end
  end

  defp start_child(shell_pid, topic_handlers, env_vars) do
    ttl = Application.get_env(:melbyd, :melbyd_sps_ttl)

    DynamicSupervisor.start_child(
      __MODULE__,
      {Melbyd.ShellProcess, %{shell_pid: shell_pid,
                             topic_handlers: topic_handlers,
                             env_vars: env_vars,
                             ttl: ttl,
                             notify_on_exit_pid: nil}}
    )
  end
end
#+end_src

* Current path (path shortening)

** Path

#+begin_src elixir :tangle daemon/lib/melbyd/path.ex
defmodule Melbyd.Path do
  @moduledoc """
  Caching wrapper around path shortening function.
  """

  require Logger

  def get_path_pretty(path, aliases, env_vars, shorten_threshold) do
    # The aliases and env_vars are lists. We leave them as such for acting as
    # keys to Cachex entries. But we do a conversion to a Map before calling the
    # Rust NIF, because the Rust functions expect a HashMap.
    {status, path_pretty} = Cachex.get(
      :path_pretty_cache,
      {path, aliases, env_vars})

    if status == :error || path_pretty == nil do
      # FIXME: Optionally colorize path depth. Maybe take in something like
      # keyword args...? Ideally user should be able to define a list of colors
      # to use for each directory depth (using modulo for cyclicness), as well
      # as the color of the slash and leading tilde (aliases).
      path_pretty =
        Melbyd.Nifs.path_shorten(
          path,
          aliases,
          env_vars,
          shorten_threshold
        )

      Cachex.put(:path_pretty_cache, {path, aliases, env_vars}, path_pretty)

      Logger.info(%{msg: "cache miss", path: path})
      path_pretty
    else
      path_pretty
    end
  end
end
#+end_src

#+begin_src rust :tangle daemon/lib/melbyd/nifs/src/path_shorten.rs
use std::collections::HashMap;
use envsubst;

#[rustler::nif]
pub fn path_shorten(path: &str,
                    aliases: HashMap<String, String>,
                    env_vars: HashMap<String, String>,
                    shorten_threshold: u8) -> String {
    let path_canonical = make_canonical_path(path, &aliases, &env_vars);
    _path_shorten(&path_canonical, shorten_threshold)
}

fn _path_shorten(path_canonical: &str, shorten_threshold: u8) -> String {
    // Don't shorten if the shorten_threshold is disabled.
    if shorten_threshold == 0 {
        return path_canonical.to_string();
    }

    // Don't shorten paths that are `shorten_threshold` characters or less in
    // length.
    if path_canonical.chars().count() <= shorten_threshold.into() {
        return path_canonical.to_string();
    }

    // Don't bother shortening anything if there is only 1 directory.
    let parts_count = path_canonical.split("/").count();
    if parts_count == 1 {
        return path_canonical.to_string();
    }
    let first_char = path_canonical.chars().next().unwrap();
    if first_char == '/' && parts_count == 2 {
        return path_canonical.to_string();
    }

    // Determine overall "search" area of possible directories within the path
    // to shorten to 1 character. We exclude from the search the very first and
    // last directories.
    let (j, shortenable_dirs) = match first_char {
        // Do not shorten leading directories that start with '~', and also do
        // not consider the root directory '/'.
        '/' | '~' => (1, 1..(parts_count - 1)),
        _ => (0, 0..(parts_count - 1)),
    };

    // Construct a set of ranges, using shortenable_dirs. E.g., if
    // shortenable_dirs is (1..3), then construct:
    //   (1..2)
    //   (1..3)
    //   (1..4).
    // We use these ranges to denote directories that should be shortened. As
    // these ranges include more and more numbers, we shorten more and more
    // directories until we are satisified with how much we've shortened
    // path_canonical.
    let mut ranges: Vec<std::ops::Range<usize>> = Vec::new();

    for i in shortenable_dirs {
        ranges.push(j..i + 1);
    }

    let mut candidate_best: Option<String> = None;
    for range in ranges {
        // Construct shortened path candidate with all directories in the range
        // shortened.
        let mut candidate: Vec<String> = Vec::new();
        for (part_idx, part) in path_canonical.split("/").enumerate() {
            if range.contains(&part_idx) {
                // Add shortened version.
                candidate.push(part.chars().next().unwrap().to_string());
            } else {
                // Add as-is.
                candidate.push(part.to_string());
            }
        }
        let shortened = candidate.join("/");
        // If a better (shorter) candidate is found, prefer it over the previous
        // candidate.
        if candidate_best.is_none()
            || shortened.chars().count() < candidate_best.as_ref().unwrap().chars().count()
        {
            candidate_best = Some(shortened);
        };

        // If a candidate is already under 30 characters, stop searching.
        if candidate_best.is_some() && candidate_best.as_ref().unwrap().chars().count() <= 30 {
            break;
        }
    }

    if candidate_best.is_none() {
        path_canonical.to_string()
    } else {
        candidate_best.unwrap().to_string()
    }
}

fn make_canonical_path(
    path: &str,
    aliases: &HashMap<String, String>,
    env_vars: &HashMap<String, String>
) -> String {
    // For every aliased path, replace all matching environment variable
    // references in the path with their actual runtime values. For example, if
    // aliases has an entry like "${HOME}/foo/bar" and "${HOME}" is set to
    // "/home/alice", then replace the name entry with
    // "/home/alice/foo/bar".
    let mut aliases_expanded: HashMap<String, String> = HashMap::new();

    // Remove env vars that have invalid values, because otherwise the envsubst
    // library chokes (even if we aren't trying to use the invalid values).
    let mut env_vars_cleaned: HashMap<String, String> = HashMap::new();
    for (k, v) in env_vars {
        let mut context: HashMap<String, String> = HashMap::new();
        context.insert(k.to_string(), v.to_string());
        if envsubst::validate_vars(&context).is_ok() {
            env_vars_cleaned.insert(k.to_string(), v.to_string());
        }
    }

    for (path_maybe_has_env_vars, name) in aliases.into_iter() {
        let expanded_path = envsubst::substitute(path_maybe_has_env_vars,
                                                 &env_vars_cleaned).unwrap();
        aliases_expanded.insert(expanded_path, name.to_string());
    }

    // Encode the shell's "~" character as a special case of our "name" idiom.
    // This way, even if no aliases match, we can replace "/home/foo" with "~".
    // FIXME: This requires HOME to be set. Otherwise we'll panic when we
    // unwrap() below.
    let home_value = env_vars.get(&"HOME".to_string()).unwrap();
    // Don't replace $HOME with "~" becausewe we already prepend every name
    // match with a "~". So defining the value here with a tilde would result in
    // a "~~".
    aliases_expanded.insert(home_value.to_string(), "".to_string());

    let path_canonical = match get_matching_name(path, &aliases_expanded) {
        // Find the longest matching expanded path in the path aliases. If there
        // is a match, then we use "~ALIAS" (the leading "~" does not mean $HOME
        // and just signifies that the word that immediately follows it is a
        // path alias). This is a Zsh-ism.
        Some((expanded_path, name)) => {
            let aliased_path = path.replacen(&expanded_path, &name, 1);
            format!("~{}", aliased_path)
        }
        // If there is no match, return the path as-is.
        None => {
            path.to_string()
        }
    };

    path_canonical
}

fn get_matching_name(
    path: &str,
    aliases: &HashMap<String, String>,
) -> Option<(String, String)> {
    let mut aliased_paths = aliases.keys().collect::<Vec<_>>();
    aliased_paths.sort();
    aliased_paths.reverse();

    for aliased_path in aliased_paths {
        if path.starts_with(aliased_path) {
            let name = aliases.get(aliased_path).unwrap();
            return Some((aliased_path.to_string(), name.to_string()));
        }
    }

    None
}

#[cfg(test)]
mod test {
    use super::*;

    #[test]
    fn test_make_canonical_path() {
        let mut aliases: HashMap<String, String> = HashMap::new();
        aliases.insert("${HOME}/bar".to_string(), "b".to_string());
        aliases.insert("${HOME}/bar/baz/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx/c".to_string(), "c".to_string());
        aliases.insert("${MYPROJECT_DIR}".to_string(), "p".to_string());
        // Handle aliases composed of multiple environment variables.
        aliases.insert("${MYPROJECT_DIR}/${KOALA_SIZE}".to_string(), "pk".to_string());

        let mut env_vars: HashMap<String, String> = HashMap::new();
        env_vars.insert("HOME".to_string(), "/home/foo".to_string());
        env_vars.insert("MYPROJECT_DIR".to_string(), "/home/foo/myproject".to_string());
        env_vars.insert("KOALA_SIZE".to_string(), "big".to_string());

        assert_eq!(make_canonical_path("", &aliases, &env_vars), "");
        assert_eq!(make_canonical_path("/", &aliases, &env_vars), "/");
        assert_eq!(make_canonical_path("/unrecognized/path", &aliases, &env_vars), "/unrecognized/path");
        assert_eq!(make_canonical_path("/home/foo", &aliases, &env_vars), "~");
        assert_eq!(
            make_canonical_path("/home/foo/bar", &aliases, &env_vars),
            "~b"
        );
        assert_eq!(
            make_canonical_path(
                "/home/foo/bar/baz/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx/c",
                &aliases,
                &env_vars,
            ),
            "~c"
        );
        assert_eq!(make_canonical_path("/home/foo/myproject", &aliases, &env_vars), "~p");
        assert_eq!(make_canonical_path("/home/foo/myproject/big", &aliases, &env_vars), "~pk");
    }

    #[test]
    fn test_path_shorten() {
        assert_eq!(_path_shorten("", 30), "");
        assert_eq!(_path_shorten("~", 30), "~");
        assert_eq!(_path_shorten("/", 30), "/");
        assert_eq!(_path_shorten("/a", 30), "/a");
        assert_eq!(_path_shorten("/a/b/c", 30), "/a/b/c");
        assert_eq!(_path_shorten("a", 30), "a");
        assert_eq!(_path_shorten("a/b/c", 30), "a/b/c");
        // If the path is exactly 30 characters, we should not shorten anything.
        assert_eq!(
            _path_shorten("/a23456789/b23456789/c23456789", 30),
            "/a23456789/b23456789/c23456789"
        );
        // If the path is just over 30 characters, we should shorten the first
        // directory.
        assert_eq!(
            _path_shorten("/a23456789/b23456789/c23456789d", 30),
            "/a/b23456789/c23456789d"
        );
        // Some longer directories.
        assert_eq!(
            _path_shorten("/a23456789/b23456789/c23456789/d23456789", 30),
            "/a/b/c23456789/d23456789"
        );
        assert_eq!(
            _path_shorten("a23456789/b23456789/c23456789/d23456789", 30),
            "a/b/c23456789/d23456789"
        );
        // Shortening of aliases (directories with "~") in them are forbidden.
        assert_eq!(
            _path_shorten("~a23456789/b23456789/c23456789/d23456789", 30),
            "~a23456789/b/c/d23456789"
        );
        // Realistic example (last directory remains untouched).
        assert_eq!(
            _path_shorten("~/prog/foreign/git/contrib/thunderbird-patch-inline", 30),
            "~/p/f/g/c/thunderbird-patch-inline"
        );
        // Extreme cases.
        assert_eq!(
            _path_shorten(
                "~/aaaaaaaaaaaaaaaaaaaa/bbbbbbbbbbbbbbbbbbbbbb/cccccccccccccccccccccc/hello", 30
            ),
            "~/a/b/c/hello"
        );
        // Unusual case of just 2 directories, where both are very long.
        assert_eq!(
            _path_shorten(
                "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb", 30
            ),
            "a/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb"
        );
        // Non-ASCII (exactly 30 characters).
        assert_eq!(
            _path_shorten("/일이삼사오육칠팔구/일이삼사오육칠팔구/일이삼사오육칠팔구", 30),
            "/일이삼사오육칠팔구/일이삼사오육칠팔구/일이삼사오육칠팔구"
        );
        assert_eq!(
            _path_shorten("일이삼사오육칠팔구/일이삼사오육칠팔구/일이삼사오육칠팔구a", 30),
            "일이삼사오육칠팔구/일이삼사오육칠팔구/일이삼사오육칠팔구a"
        );
        assert_eq!(
            _path_shorten("~일이삼사오육칠팔구/일이삼사오육칠팔구/일이삼사오육칠팔구", 30),
            "~일이삼사오육칠팔구/일이삼사오육칠팔구/일이삼사오육칠팔구"
        );
        // Non-ASCII (over 30 characters).
        assert_eq!(
            _path_shorten("/일이삼사오육칠팔구/일이삼사오육칠팔구/일이삼사오육칠팔구/a", 30),
            "/일/일이삼사오육칠팔구/일이삼사오육칠팔구/a"
        );
        let longstr = concat!("~/일일일일일일일일일일일일일일일일일일일일",
                                  "/이이이이이이이이이이이이이이이이이이이이",
                                  "/삼삼삼삼삼삼삼삼삼삼삼삼삼삼삼삼삼삼삼삼",
                                  "/hello");
        assert_eq!(
            _path_shorten(longstr, 30),
            "~/일/이/삼/hello"
        );
        // Shorten threshold is disabled, so don't shorten at all.
        assert_eq!(
            _path_shorten(longstr, 0),
            longstr
        );
    }
}
#+end_src

** Caching

We use caching for the path shortening logic. We avoid re-shortening a given
path if we've seen the same inputs before.

We only keep a cache size of 256 because in practice we only move around a
handful of directories during a typical computing session.

#+begin_src elixir :tangle daemon/lib/melbyd/cache.ex
defmodule Melbyd.Cache.PathShorten do
  @moduledoc """
  path-shorten Cache
  """
  @cache_id :path_pretty_cache

  def child_spec(_init_arg) do
    %{
      id: @cache_id,
      type: :supervisor,
      start:
        {Cachex, :start_link,
         [
           @cache_id,
           [
             limit: 256
           ]
         ]}
    }
  end
end
#+end_src

* Colors

We use [[https://github.com/mazznoer/csscolorparser-rs][=csscolorparser=]] to parse a wide variety of ways to represent colors. The
point of using a NIF here isn't so much about speed, but more about the
convenience of being able to use this library.

#+begin_src rust :tangle daemon/lib/melbyd/nifs/src/color.rs
use csscolorparser::Color;

#[derive(rustler::NifTuple, Default, Debug, PartialEq, Eq)]
pub struct Color24BitRust {
    pub red: u8,
    pub green: u8,
    pub blue: u8,
    pub alpha: u8,
}

#[rustler::nif]
pub fn parse_color(color_str: &str) -> Color24BitRust {
    let vals = match color_str.parse::<Color>() {
        Ok(color) => color.to_rgba8(),
        Err(e) => {
          eprintln!("{:?} {:?}", e, color_str);
          [127, 127, 127, 255]
        }
    };

    Color24BitRust {
        red: vals[0],
        green: vals[1],
        blue: vals[2],
        alpha: vals[3],
    }
}

fn _parse_color(color_str: &str) -> [u8; 4] {
    match color_str.parse::<Color>() {
        Ok(color) => color.to_rgba8(),
        Err(e) => {
          eprintln!("{:?} {:?}", e, color_str);
          [127, 127, 127, 255]
        }
    }
}

#[cfg(test)]
mod test {
    use super::*;

    #[test]
    fn test_parse_color() {
        assert_eq!(_parse_color("#ff0000"), [255, 0, 0, 255]);
        // Invalid strings get parsed as grey.
        assert_eq!(_parse_color(""), [127, 127, 127, 255]);
        assert_eq!(_parse_color("?"), [127, 127, 127, 255]);
        assert_eq!(_parse_color("hello world"), [127, 127, 127, 255]);
    }
}
#+end_src

#+begin_src elixir :tangle daemon/lib/melbyd/color.ex
defmodule Melbyd.Color do
  @moduledoc """
  Color parsing.
  """

  require Logger

  def parse(color_str) do
    {r, g, b, _a} = Melbyd.Nifs.parse_color(color_str)
    {r, g, b}
  end
end
#+end_src
