# Copyright 2023 Linus Arver
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#+title: Controller
#+PROPERTY: header-args :noweb no-export

* Entrypoint for client

This is where we start the Elixir program. There are lots of bits in here, but
the main thing we should care about for now is the =Melbyd.GRPC= module, which
acts as the entrypoint for clients using gRPC. The REST API is deprecated and
will be deleted in the future (to be replaced entirely with gRPC calls).

#+name: application.ex
#+caption: =Melbyd.Application=
#+begin_src elixir :tangle daemon/lib/melbyd/application.ex
defmodule Melbyd.Application do
  # See https://hexdocs.pm/elixir/Application.html
  # for more information on OTP Applications
  @moduledoc false

  use Application
  require Logger

  @impl true
  def start(_type, _args) do
    # Make sure the ~/.melby/tzdata directory exists.
    File.mkdir_p!(Path.expand("~/.melby/tzdata"))

    children = [
      # (model)
      #
      # Equivalent to {Melbyd.Cache.PathShorten, []} --- and now this module must
      # define its own child_spec(arg) function.
      Melbyd.Cache.PathShorten,

      # Equivalent to {Task.Supervisor, [name: Melbyd.TaskSupervisor]}
      {Task.Supervisor, name: Melbyd.TaskSupervisor},
      Melbyd.StandardResourceSupervisor,
      Melbyd.ShellProcessSupervisor,

      # Lua config validation cache
      Melbyd.LuaConfigValidation,

      # PubSub messaging system. The "Melbyd.PubSub" here is just an atom, not an
      # actual Elixir Module. The sole purpose of it is to be a unique name,
      # from Phoenix.PubSub's perspective.
      {Phoenix.PubSub, name: Melbyd.PubSub},

      # gRPC service. (controller)
      {GRPC.Server.Supervisor, endpoint: Melbyd.GRPC, port: Application.get_env(:melbyd, :melbyd_port), start_server: true},

      # Haskell "melbyr" service. (view)
      __NREF__melbyr_muontrap
    ]

    # See https://hexdocs.pm/elixir/Supervisor.html
    # for other strategies and supported options
    opts = [strategy: :one_for_one, name: Melby.Supervisor]

    announce()

    Supervisor.start_link(children, opts)
  end

  # FIXME: Add ASCII-art here.
  defp announce() do
    Logger.info("Starting application in #{Application.fetch_env!(:melbyd, :env)} environment")
  end
end
#+end_src

** melbyr dependency

Interacting with the view requires us to call into melbyr (Haskell server) from
Elixir. We need to:

1. run the melbyr server, and
2. call its gRPC methods to interact with it.

The first part is guaranteed by using the [[https://github.com/fhunleth/muontrap][MuonTrap]] library which handles running
OS processes reliably (restarting them if they crash). The second part is
handled by the Melbyd Lua SDK, where the call path goes from the user-provided
Lua, to Elixir, then finally to melbyr (Haskell) via gRPC.

The =stderr_to_stdout: true= redirects the stderr messages (which the Haskell
binary uses for printing logs) to stdout, and the =log_output: :debug= forwards
all stdout to the =Logger=. The disadvantage is that this forwarding to =Logger=
is done piecemeal in 256-byte chunks at a time (probably for performance
reasons), so any logs longer than 256 characters get chopped up into multiple
=Logger= messages. But the advantage is that we can control the log output
behavior of the Haskell binary during integration tests (to silence all Logger
output for passing tests, as per
https://hashrocket.com/blog/posts/silence-logger-messages-in-exunit).

#+name: __NREF__melbyr_muontrap
#+begin_src elixir
{MuonTrap.Daemon,
 [Application.get_env(:melbyd, :melbyr_path),
  ["serve", "#{Application.get_env(:melbyd, :melbyr_port)}"],
 # FIXME: Make this more verbose output an environment variable option.
 #[stderr_to_stdout: true, log_output: :debug]]},
 [stderr_to_stdout: false]]},
#+end_src

* gRPC services

The most important way of interaction between the client and melbyd is the
=GetView= RPC method (FIXME: add link). This method takes in a Lua script, which
will be responsible for both collecting the necessary data and arranging it to
generate the view. So we let the client decide what to collect and display.

We serve clients through gRPC services. If you look at the proto file (FIXME:
add link), there is a single View service.

The View service is shown below.

#+begin_src elixir :tangle daemon/lib/melbyd/grpc.ex
defmodule Melbyd.GRPC do
  use GRPC.Endpoint

  intercept GRPC.Server.Interceptors.Logger, level: :info

  run Melbyd.View.Service
end

defmodule Melbyd.View.Service do
  use GRPC.Server, service: MelbyClient.View.Service, compressors: [GRPC.Compressor.Gzip]

  @moduledoc """
  Legacy.
  """

  @doc """
  Retrieves the prompt.
  """
  @spec get_view(MelbyClient.ViewRequest.t(), GRPC.Server.Stream.t()) ::
          MelbyClient.ViewResponse.t()
  def get_view(req, _stream) do
    Melbyd.View.generate(req)
  end
end
#+end_src

Notice that we define the toplevel =Melbyd.Endpont= module, which contains the
=View= service.

** View (melbyr interface)

Below is =melby-client='s =ViewRequest= that we handle. As part of handling this,
we will need to call out to the melbyr Haskell server over gRPC.

#+begin_src elixir :tangle daemon/lib/melbyd/view.ex
defmodule Melbyd.View do
  @moduledoc """
  Module to generate an arbitrary view (string).
  """

  require Logger

  def generate(req) do
    config_path = req.config_path
    env_vars = req.env_vars
    shell_pid = req.shell_pid

    Logger.info("interpreting config #{inspect(config_path)}")
    Logger.info("MELBY_DIR is #{inspect(env_vars["MELBY_DIR"])}")

    with :ok <- validate(config_path, env_vars, shell_pid),
         {:ok, view_params_types} <- Melbyd.LuaConfigValidation.validate(config_path),
         {:ok, env_vars_reduced} <- Melbyd.LuaConfigValidation.enforce_view_params_types(view_params_types, env_vars),
         {:ok, val} when is_list(val) and val != [] and is_binary(hd(val)) <-
           Melbyd.LuaInterop.run(config_path, ["Config", "view"], [env_vars_reduced, shell_pid]) do
      [view] = val

      %MelbyClient.ViewResponse{
        status: :VIEW_STATUS_OK,
        view: view
      }
    else
      {:error, reason} ->
        %MelbyClient.ViewResponse{
          status: :VIEW_STATUS_ERROR,
          error: IO.inspect(reason)
        }

      unrecognized ->
        %MelbyClient.ViewResponse{
          status: :VIEW_STATUS_ERROR,
          error: "backend returned an unrecognized response: #{inspect(unrecognized)}"
        }
    end
  end

  # Perform some rudimentary validation.
  # FIXME: Is this even worth it?
  def validate(config_path, _env_vars, shell_pid) do
    cond do
      !File.exists?(config_path) ->
        {:error, "file #{config_path} does not exist"}

      String.length(shell_pid) == 0 ->
        {:error, "shell_pid cannot be an empty string"}

      !String.match?(shell_pid, ~r/^[[:digit:]]+$/) ->
        {:error, "shell_pid '#{shell_pid}' has non-digit characters in it"}

      true ->
        :ok
    end
  end
end
#+end_src

** Standard Resource Service

The Standard Resource Service (SRS) is a general-purpose Elixir GenServer with a
notion of history of previous states. The two main selling points are:

1. it can be used to implement the Kubernetes controller pattern (FIXME: insert
   link); and
2. unlike typical Elixir GenServers, it can be configured at runtime with Lua.

SRS was designed to solve the problem of long-running shell commands that are
long enough to be annoying but short enough that little effort has gone into
making the command run any faster, and where the output of the command doesn't
change that frequently. A good example is a "git status" command that takes 2 or
3 seconds or longer for large repositories. Another example might be calculating
the disk space usage of a particularly large folder with many files in it. SRS
allows users to encode these expensive shell commands into an Elixir GenServer
(a long-lived, lightweight thread that stores state), such that the output is
cached and only invalidated (and recomputed) based on user-defined conditions.
These user-defined conditions can be arbitrary, but SRS comes with some standard
ones such as file modification events. Other event producers are possible, such
as ones over the network (e.g., email inbox, pub-sub events, etc).

*** Motivation

The original motivation behind SRS was the realization that most of the
functionality of the GitWatcher system was not unique to it and could be
generalized beyond just =git=.

A secondary motivation is that this enables using melbyc to create other
SRS-backed Resources at runtime (just like =kubectl apply -f ...=), and also
naturally lends itself to more introspection (we should be able to do =melbyc get
RESOURCE foo= just like how we can do =kubectl get RESOURCE=).

* Lua API

We provide a Lua API for =melbyc= (our users) because we want to make it easy to
configure advanced functionality for generating the prompt. There are 3 modules
here:

- *Melbyd.LuaInterop* :: Expose Lua capability to the rest of melbyd
- *Melbyd.LuaSdk* :: Autoloaded "Melbyd Lua SDK"
- *Melbyd.LuaSdkAutoload* :: Boilerplate to make Melbyd.LuaSdk easier to write.
  Defines a behaviour that can be implemented by any other Elixir module that
  wants to be exposed to the Lua environment.

** =Melbyd.LuaInterop=

This module extends Melbyd with Lua. It is able to read and execute Lua (5.2)
scripts. The Melbyd "API" is exposed to the script with the =def_lua_func= macro,
where we define an Elixir function to expose to the Lua code. The Elixir
functions are much more powerful than the Lua functions that the user can
define, because they have full access to all of the rest of Melbyd. All of the
Elixir functions are exposed under the "melbyd" Lua table (see =run_file/1=).

Practically speaking, this module is meant to allow users to configure the
output of melbyc. That is, users pass in a Lua script location to melbyc, and that
script gets executed here, and finally the result of that script is returned to
melbyc.

#+name: lua_api.ex
#+caption: =Melbyd.LuaInterop=
#+begin_src elixir :tangle daemon/lib/melbyd/lua_api.ex
defmodule Melbyd.LuaInterop do
  @moduledoc false

  def run(lua_file, func_path, func_args) do
    with {:ok, _, st} <- run_file(lua_file),
         {res, _st} <- Luerl.call_function(st, func_path, func_args) do
      # Now that we have the Lua state with all custom callback functions loaded
      # inside it (as well as calls to our Elixir Melbyd SDK), we can piece
      # together what the user wants.
      {:ok, res}
    else
      reason -> {:error, "#{inspect(reason)}"}
    end
  end

  def run_file(lua_file) do
    with st0 <- Luerl.init(),
         # Expose Melbyd API functions (everything inside Melbyd.LuaSdk).
         st1 <- Luerl.load_module(st0, ["melbyd"], Melbyd.LuaSdk),
         # We must run "dofile" because otherwise nothing is loaded. That is, if
         # the Lua file has "function ... end" definitions and nothing else, the
         # only way to load these functions is to run Luerl.dofile/1 here. If we
         # use Luerl.loadfile/1 instead, the custom Lua functions are not loaded
         # into the state.
         {res, st2} <- Luerl.dofile(st1, String.to_charlist(lua_file)) do
      {:ok, res, st2}
    else
      reason -> {:error, "#{inspect(reason)}"}
    end
  end
end

__NREF__melbyd_lua_config_validation
__NREF__melbyd_luasdkhelper
__NREF__melbyd_luasdk
__NREF__melbyd_luerl_util
#+end_src

*** Validation

Validation of a user's Lua configuration involves running the bulk of the given
configuration, but through a special, modifed Lua SDK environment where all
inputs to the configuration are controlled.

The steps involved are roughly:
1. Modify the SRS reader functions to read the "fake" fixture data that are part
   of each SRS's definition
2. Run the "Config.view" function, using a set of fake environment variables
3. Check that the result from step 2 contains some substrings we expect to get
   (also defined in the Lua config).
4. Repeat steps 2 and 3 for each "Config.view_tests" entry defined in the Lua
   config.

When the above steps are being executed, purely for validation, we don't expect
any of the resulting side effects to interfere with the real side effects of
interperting the Lua configuration for production. This is important because as
a matter of principle, the test and production environments should never have
any overlap.

#+name: __NREF__melbyd_lua_config_validation
#+begin_src elixir
import Cachex.Spec

defmodule Melbyd.LuaConfigValidation do
  require Logger

  # FIXME: Add Cachex lookup to see if this config was validated previously. We
  # should add this lookup after we've implemented the validation functionality
  # completely.
  #
  # FIXME: (For caching) We should require env vars (which we use) to be
  # declared ahead of time, and hash the *names* of these env vars (not their
  # contents) as required inputs (you can think of them as types) to a function
  # (this Lua config). And then if the config does not declare this list of env
  # vars, we can refuse to validate it. This way we capture the exact "function
  # definition", so to speak, of the Lua config by precisely describing its
  # definition.
  def validate(lua_file) do
    with st0 <- Luerl.init(),
         st1 <- Luerl.load_module(st0, ["melbyd"], Melbyd.LuaSdk),
         # Overwrite "read_standard_resource" with the fake version. Note that
         # this __handle_lua_call__... function is defined by the def_lua_func
         # macro for the "read_standard_resource_fake" function. We have to use
         # Luerl.set_table1/3 (with the tuple form of {:erl_func, func_ref}) and
         # not Luerl.set_table/3 (which we can use with just the func_ref alone
         # as the 3rd argument --- this passes compilation), because we already
         # perform encoding back for Luerl inside all __handle_lua_call__...
         # functions. Otherwise we would be encoding twice.
         st2 <-
           Luerl.set_table1(
             st1,
             ["melbyd", "read_standard_resource"],
             {:erl_func, &Melbyd.LuaSdk.__handle_lua_call__read_standard_resource_fake/2}
           ),
         # Overwrite the "get_path_aliases" function to use the contents of the
         # variable directly (instead of doing I/O to read the given path).
         st3 <-
           Luerl.set_table1(
             st2,
             ["melbyd", "get_path_aliases"],
             {:erl_func, &Melbyd.LuaSdk.__handle_lua_call__get_path_aliases_fake/2}
           ),
         {_, st4} <- Luerl.dofile(st3, String.to_charlist(lua_file)),
         vm_fingerprint <- get_vm_fingerprint(st4),
         {res, view_params_types} <-
           Cachex.fetch(:lua_config_validation_cache, {lua_file, vm_fingerprint}) do
      case res do
        :ok -> {:ok, view_params_types}
        :commit -> {:ok, view_params_types}
        :ignore -> {:error, "failed cache key validation"}
        :error -> {:error, "failed cache key validation2"}
      end
    else
      e -> {:error, e}
    end
  end

  # Return the blank state of the initial Lua VM state meant for validation
  # purposes only.
  #
  # FIXME: Add a fake for SPS also? And also delete it when we're done with
  # validation?
  def preloaded_fake_lua_vm() do
    Luerl.init()
    |> Luerl.load_module(["melbyd"], Melbyd.LuaSdk)
    # Overwrite "read_standard_resource" with the fake version. Note that this
    # __handle_lua_call__... function is defined by the def_lua_func macro for
    # the "read_standard_resource_fake" function. We have to use
    # Luerl.set_table1/3 (with the tuple form of {:erl_func, func_ref}) and not
    # Luerl.set_table/3 (which we can use with just the func_ref alone as the
    # 3rd argument --- this passes compilation), because we already perform
    # encoding back for Luerl inside all __handle_lua_call__... functions.
    # Otherwise we would be encoding twice.
    |> Luerl.set_table1(
      ["melbyd", "read_standard_resource"],
      {:erl_func, &Melbyd.LuaSdk.__handle_lua_call__read_standard_resource_fake/2}
    )
    # Overwrite the "get_path_aliases" function to use the contents of the
    # variable directly (instead of doing I/O to read the given path).
    |> Luerl.set_table1(
      ["melbyd", "get_path_aliases"],
      {:erl_func, &Melbyd.LuaSdk.__handle_lua_call__get_path_aliases_fake/2}
    )
  end

  def validate_key({lua_file, vm_fingerprint}, preloaded_fake_lua_vm) do
    # We already declare the env var names we want to use in
    # our config, so we don't actually need the env_vars at all to be part of
    # the cache key..! So just
    # reading the lua_file (which itself declares the exact env vars we need) is
    # enough.

    # For deletion of the side effects (SRS, etc) generated via validation, the
    # strategy is to use the vm_fingerprint. We store the fingerprint inside the
    # Lua VM state. Then when the fake versions of read_standard_resource are
    # called, they save this vm_fingerprint as part of their ID. Then we call a
    # "cleanup side effects" function directly right here with the
    # vm_fingerprint. Then this cleanup function broadcasts a shutdown message
    # to all resources with this vm_fingerprint. We have to only delete the
    # fakes that were generated as part of validing this particular
    # vm_fingerprint, because otherwise we would be deleting other resources
    # that might be in the middle of validating a different Lua config.
    with {_, st1} <- Luerl.dofile(preloaded_fake_lua_vm, String.to_charlist(lua_file)),
         view_params_types <- get_view_params_types(st1),
         :ok <- assert_expected_views(st1, view_params_types, vm_fingerprint) do
      # FIXME: Maybe store some more useful metrics beyond just
      # "view_params_types". E.g., the number of test cases executed, how long
      # it took to run it (at what time), etc.
      {:commit, view_params_types}
    else
      # If there's any error, abort and return nil.
      err ->
        Logger.warning("got error: #{inspect(err)}")
        {:ignore, nil}
    end
  end

  # This checks the types of the actual env_vars from the real environment.
  def get_view_params_types(st0) do
    {view_params_types_tuples, _st} = Luerl.get_table(st0, ["Config", "view_params_types"])

    view_params_types =
      view_params_types_tuples
      |> Melbyd.LuerlUtil.table_to_native_map()

    Map.put(
      view_params_types,
      "env",
      view_params_types["env"]
      |> Melbyd.LuerlUtil.table_to_native_map()
    )
  end

  def enforce_view_params_types(view_params_types, env_vars) do
    errors =
      Enum.reduce(view_params_types["env"], [], fn {name, type_array}, errors ->
        [req_or_opt, type] =
          type_array
          |> Melbyd.LuerlUtil.array_to_native_list()

        required = req_or_opt == "required"

        # Check vals of real env_vars.
        case assert_env_var_type(env_vars, name, required, type) do
          :ok -> errors
          {:error, reason} -> ["#{name}: " <> reason | errors]
        end
      end)

    if errors == [] do
      # Reduce the env_vars map to only include the env_vars listed in view_params_types.
      env_vars_reduced =
        Enum.reduce(env_vars, %{}, fn {k, _}, env_vars_reduced ->
          val = Map.fetch!(env_vars, k)
          Map.put(env_vars_reduced, k, val)
        end)

      {:ok, env_vars_reduced}
    else
      {:error, Enum.join(errors, "\n")}
    end
  end

  def assert_env_var_type(env_vars, name, required, type) do
    with {:ok, val} <- Map.fetch(env_vars, name),
         :ok <- assert_maybe_required(name, val, required) do
      case type do
        "path" ->
          assert_type_path(val)

        "paths" ->
          assert_type_paths(val)

        # The contents of a file can be anything (any sequence of bytes), so it's always well-formed.
        "pathblob" ->
          :ok

        "int" ->
          assert_type_int(val, false)

        "uint" ->
          assert_type_int(val, true)

        # Expect the string to be composed of at least 1 non-whitespace character.
        "string" ->
          if String.trim(val) == "" do
            {:error, "string must have at least 1 non-whitespace character"}
          else
            :ok
          end

        t ->
          {:error, "unrecognized type #{t}"}
      end
    else
      err ->
        case err do
          :error ->
            if required do
              {:error, "env var #{name} required but does not exist"}
            else
              :ok
            end

          e ->
            {:error, "urecognized error #{inspect(e)}"}
        end
    end
  end

  def assert_maybe_required(name, val, required) do
    if required do
      if String.length(val) == 0 do
        {:error, "env var #{name} is required, but it is set to the empty string"}
      else
        :ok
      end
    else
      :ok
    end
  end

  def assert_type_int(maybe_int, unsigned) do
    try do
      int = String.to_integer(maybe_int)

      if unsigned do
        if int < 0 do
          {:error, "not a uint: #{maybe_int} is negative"}
        else
          :ok
        end
      else
        :ok
      end
    rescue
      e -> {:error, "not an integer: #{maybe_int}: #{Exception.message(e)}"}
    end
  end

  def assert_type_path(path) do
    # FIXME: use haskell parsec to do a full parse

    # Use a basic heuristic. Assert that the first character starts with a slash
    # "/", that the last character is not a slash, and that there are no runs of
    # consecutive slashes. No null bytes. Last character cannot  be "." (this
    # includes the case where the last 2 characters are ".").

    cond do
      String.length(path) == 0 -> {:error, "cannot be empty"}
      String.first(path) != "/" -> {:error, "first character must be a slash"}
      String.last(path) == "/" -> {:error, "last character cannot be a slash"}
      String.last(path) == "." -> {:error, "last character cannot be a dot"}
      String.contains?(path, "//") -> {:error, "consecutive slashes are forbidden"}
      String.contains?(path, "\0") -> {:error, "cannot contain a null byte"}
      true -> :ok
    end
  end

  def assert_type_paths(paths) do
    # FIXME: use haskell parsec to do a full parse

    # Use a basic heuristic. Assert that the first character starts with a slash
    # "/", that the last character is not a slash, and that there are no runs of
    # consecutive slashes. No null bytes. Last character cannot  be "." (this
    # includes the case where the last 2 characters are ".").

    error_reasons =
      String.split(paths, ":")
      |> Enum.reduce([], fn path, error_reasons ->
        case assert_type_path(path) do
          {:error, reason} -> [reason | error_reasons]
          _ -> error_reasons
        end
      end)

    if error_reasons == [] do
      :ok
    else
      {:error, error_reasons}
    end
  end

  # FIXME: Each of the SRS models have a "fake" field with faked readers in it
  # (which return plausible, well-formatted data). We just have to use them
  # somehow.
  #
  # We can make this fake tick runner just run the ["Config", "view"] function
  # in the Lua state, wait 1 second, check the result and compare it to the
  # expectation, and repeat. The expectations can come from the config file
  # itself (add it under another key path). The behind the scenes the
  # StandardResource should behave almost like in prod, but with the difference
  # that it'll run the fake readers instead of the actual readers, as well as
  # provision the SRS GenServer in a different namespace so as not to clash with
  # the production resources.

  # The config should tell us how many "ticks" and corresponding expectations to
  # run. We could enforce a minimum of 3 rounds from our side (i.e., fail
  # validation if the user has not configured at lesat 3 rounds of
  # expectations).
  #
  # Each iteration should be:
  #
  #     1. Execute ["Config", "view"] function in the Lua VM state (time_idx is 1).
  #
  #     2. Expectation: check expected return value of the above versus what we
  #     actually got (got vs want).
  #
  #     3. Increment time_idx by 1, and re-run step 1. Continue until time_idx
  #     == 10 or some other number.
  def assert_expected_views(st0, view_params_types, vm_fingerprint) do
    # Set the vm_fingerprint inside the Lua VM, so that the fake Lua SDK
    # functions can use them to pass them on to Elixir.
    st1 = Luerl.set_table1(st0, ["melbyd", "vm_fingerprint"], vm_fingerprint)

    # 'expectations' is a list of list of substrings we need to match after
    # calling ["Config", "view"].
    {view_tests_tuples, _st} = Luerl.get_table(st1, ["Config", "view_tests"])

    view_tests =
      view_tests_tuples
      |> Melbyd.LuerlUtil.array_to_native_list()
      |> Enum.map(&Melbyd.LuerlUtil.table_to_native_map/1)

    # For each expectation in the expectations, run the Config.view() function.
    # Because we are running fake resources, the read() call will be synchronous
    # and force a re-read, incrementing the :read field in every SRS each time.
    errors =
      Enum.reduce(view_tests, [], fn view_test, errors ->
        # Check vals of fake env_vars in view_tests.
        env_vars_fake = view_test["env"] |> Melbyd.LuerlUtil.table_to_native_map()

        # FIXME: dedupe this logic (copied from enforce_view_params_types)
        type_errors =
          Enum.reduce(view_params_types["env"], [], fn {name, type_array}, errors ->
            [req_or_opt, type] =
              type_array
              |> Melbyd.LuerlUtil.array_to_native_list()

            required = req_or_opt == "required"

            # Check vals of real env_vars.
            case assert_env_var_type(env_vars_fake, name, required, type) do
              :ok -> errors
              {:error, reason} -> ["#{name} (view_test): " <> reason | errors]
            end
          end)

        if type_errors == [] do
          case assert_expected_view(st1, view_test, env_vars_fake) do
            :ok -> errors
            {:error, errs} -> [errs | errors]
          end
        else
          type_errors ++ errors
        end
      end)

    # Send message to delete all fake SRS GenServers, because we're done using
    # them. We won't need them until we need to run this function again, which
    # will only happen when the cache entry for this vm_fingerprint expires
    # (which should technically only happen when melbyd restarts).
    Phoenix.PubSub.broadcast(
      Melbyd.PubSub,
      "fake_" <> vm_fingerprint,
      {:EXIT, self(), :release_fake_resource}
    )

    if Kernel.length(errors) > 0 do
      Logger.warning("got #{Kernel.length(errors)} errors reading fake readers")
      errors |> Enum.map(fn e -> Logger.warning(e) end)
      "failed validation"
    else
      :ok
    end
  end

  defp assert_expected_view(st0, view_test, env_vars_fake) do
    substrings = view_test["expected_substrings"] |> Melbyd.LuerlUtil.array_to_native_list()

    {[got], _st} = Luerl.call_function(st0, ["Config", "view"],
                                       [env_vars_fake, "000"])

    errors =
      Enum.reduce(substrings, [], fn substring, errors ->
        if String.contains?(got, substring) do
          errors
        else
          ["could not find #{inspect(substring)} inside #{inspect(got)}" | errors]
        end
      end)

    if errors == [] do
      :ok
    else
      {:error, errors}
    end
  end

  def get_vm_fingerprint({a, b, c, d, e, f, g, h, i, _j, _k, l, m}) do
    {a, b, c, d, e, f, g, h, i, l, m}
    |> Kernel.inspect(
      limit: :infinity,
      printable_limit: :infinity,
      width: :infinity
    )
    |> (&:crypto.hash(:sha, &1)).()
    # Make this fingerprint easier to debug.
    |> Base.encode16()
  end

  # Cache for storing a boolean of whether this config has already been
  # validated or not.
  @cache_id :lua_config_validation_cache

  def child_spec(_init_arg) do
    %{
      id: @cache_id,
      type: :supervisor,
      start:
        {Cachex, :start_link,
         [
           @cache_id,
           [
             limit: 16,
             fallback: fallback(default: &validate_key/2, state: preloaded_fake_lua_vm())
           ]
         ]}
    }
  end
end
#+end_src

** Auto-loaded Elixir module exposed to Lua (=Melbyd.LuaSdk=)

The code here is inspired by
https://github.com/ConnorRigby/lou/blob/master/lib/lou/lua/discord.ex. But
basically the idea is that we can write a single Elixir module (=Melbyd.LuaSdk=)
which will get loaded into Lua. Theoretically we could have multiple such
auto-loaded modules, but currently there is no need.

There are basically 2 categories of functions we expose to Lua:

1. functions to fetch data (Git data, etc), and
2. functions to format the data for saving into the shell's =$PS1= prompt
   variable.

The Elixir functions must all take 2 arguments: the first argument is a list
which captures the function arguments sent from the Lua side, and the second
argument is always the state of the Lua VM instance. This is demonstrated in the
=hello_names= function (see section [[*Tests]]).

#+name: __NREF__melbyd_luasdk
#+begin_src elixir
defmodule Melbyd.LuaSdk do
  @moduledoc """
  An Elixir module that can be accessed from Lua (via luerl).
  """

  # This declaration just prevents programmer errors where we forget to define
  # install/1.
  @behaviour Melbyd.LuaSdkLoadable

  # Autogenerate some boilerplate to avoid having to manually define
  # autoloaded_functions_table(). Specifically it defines the install/1 and
  # loaded_functions_table/0 for us automatically.
  use Melbyd.LuaSdkLoadable

  require Logger

  @newlines ["\n", "\r", "\r\n", "\n\r"]

  def get_melbyr_addr() do
    "localhost:#{Application.get_env(:melbyd, :melbyr_port)}"
  end

  __NREF__melbyd_luasdk_render
  __NREF__melbyd_luasdk_get_path_pretty
  __NREF__melbyd_luasdk_get_colorized_sha
  __NREF__melbyd_luasdk_get_time
  __NREF__melbyd_luasdk_to_shell_script

  __NREF__melbyd_luasdk_srs
  __NREF__melbyd_luasdk_srs_fake
  __NREF__melbyd_luasdk_srs_helpers

  __NREF__melbyd_luasdk_pubsub
  __NREF__melbyd_luasdk_sps

  __NREF__melbyd_luasdk_misc
end
#+end_src

*** Render widgets (convert string "objects" into strings with ANSI escape codes)

#+name: __NREF__melbyd_luasdk_render
#+begin_src elixir
def_lua_func render([widgets_list_ref, delimiter_ref], st0) do
  delimiter_tuples = Luerl.decode(st0, delimiter_ref)
  delimiter = widget_from_tuples(delimiter_tuples)

  # Retrieve render_options from the Config table in the Lua state.
  render_options = get_render_options(st0)

  widgets =
    Luerl.decode(st0, widgets_list_ref)
    |> Enum.map(fn {_idx, widget_tuples} ->
      widget_from_tuples(widget_tuples)
    end)

  req = %MelbyRenderer.RenderWidgetsRequest{}
  req = Map.put(req, :widgets, widgets)
  req = Map.put(req, :delimiter, delimiter)
  req = Map.put(req, :render_options, render_options)

  # Call out to melbyr over gRPC.
  addr = get_melbyr_addr()
  with {:ok, channel} <- GRPC.Stub.connect(addr),
       {:ok, reply} <- MelbyRenderer.Renderer.Stub.render_widgets(channel, req, timeout: 200) do
    GRPC.Stub.disconnect(channel)
    {:ok, reply.widgets_rendered, st0}
  else
    err -> raise "could not parse response from melbyr: #{inspect(err)}"
  end
end

def get_render_options(st0) do
  {render_options_tuples, _st1} = Luerl.get_table(st0, ["Config", "render_options"])

  render_options_map =
    Map.new(
      render_options_tuples
      |> Enum.map(fn {k, v} -> {String.to_atom(k), String.to_atom(v)} end)
    )

  render_options = %MelbyRenderer.RenderOptions{}
  Map.merge(render_options, render_options_map)
end

def widget_from_tuples(widget_tuples) do
  {widget, tp} =
    Enum.reduce(
      widget_tuples,
      {%MelbyRenderer.Widget{}, %MelbyRenderer.TextProperty{}},
      fn {k, v}, acc ->
        {acc_w, acc_tp} = acc
        # We only recognize certain keywords.
        case k do
          "str" ->
            {Map.put(acc_w, :str, v), acc_tp}

          "fg" ->
            {acc_w, Map.put(acc_tp, :fg, color_from_str(v))}

          "bg" ->
            {acc_w, Map.put(acc_tp, :bg, color_from_str(v))}

          "styles" ->
            styles = Enum.map(v, fn {_idx, s} -> style_from_str(s) end)
            {acc_w, Map.put(acc_tp, :styles, styles)}

          # Skip over any unrecognized key.
          "drop_delim_left" ->
            {Map.put(acc_w, :drop_delim_left, v), acc_tp}

          "drop_delim_right" ->
            {Map.put(acc_w, :drop_delim_right, v), acc_tp}

          _ ->
            acc
        end
      end
    )

  Map.put(widget, :prop, tp)
end

def color_from_str(s) do
  {r, g, b} = Melbyd.Color.parse(s)
  c24bit = %MelbyRenderer.Color24Bit{red: r, green: g, blue: b}
  %MelbyRenderer.Color{color_oneof: {:color_24_bit, c24bit}}
end

def style_from_str(s) do
  case s do
    "bold" -> :TEXT_STYLE_BOLD
    # FIXME: skip over unrecogized values
    _ -> :TEXT_STYLE_BOLD
  end
end
#+end_src

*** Pretty paths

#+name: __NREF__melbyd_luasdk_get_path_pretty
#+begin_src elixir
def_lua_func get_path_pretty([path, options_ref], st0) do
  options = Luerl.decode(st0, options_ref)
  options_map = Map.new(options)

  aliases = options_map["aliases"] |> Melbyd.LuerlUtil.table_to_native_map()
  env = options_map["env"] |> Melbyd.LuerlUtil.table_to_native_map()

  # Create a subset of env vars. This is because we only care about the ones used by the keys in aliases.
  {aliases_filtered, env_filtered} =
    Enum.reduce(aliases, {%{}, %{}}, fn {k, v}, {aliases_filtered, env_filtered} ->
      vars = Regex.scan(~r/\$\{(.+?)\}/, k) |> Enum.map(fn [_entire_match, group] -> group end)
      # Check if every variable is found in env.
      env_subset = Map.take(env, vars)

      if length(vars) == Enum.count(env_subset) do
        # Only keep aliases if we can find all of its environment variable references.
        {Map.put(aliases_filtered, k, v), Map.merge(env_filtered, env_subset)}
      else
        {aliases_filtered, env_filtered}
      end
    end)

  # If we were unable to parse the aliases (e.g., we are given no aliases to
  # begin with because we failed to parse the path aliases file), then just use
  # a map with the HOME variable. This is because the Rust NIF always
  # expects at least the "HOME" env var to exist.
  env_filtered_final =
    if env_filtered == %{} do
      if env["HOME"] == nil do
        Logger.warning(
          "HOME environment variable is not defined; using useless default \"/home/foo\""
        )
      end

      Map.new([{"HOME", env["HOME"] || "/home/foo"}])
    else
      env_filtered
    end

  # Default value is 0 (no shortening).
  shorten_threshold = Map.get(options_map, "shorten_threshold", 0)

  prettified =
    Melbyd.Path.get_path_pretty(path, aliases_filtered, env_filtered_final, shorten_threshold)

  {:ok, prettified, st0}
end

def_lua_func get_path_aliases([path_aliases_file], st0) do
  if path_aliases_file == nil do
    Logger.warning("path_aliases_file is nil; defaulting to empty map")
    {:ok, Map.new(), st0}
  else
    with {:ok, path_aliases_raw} <- File.read(path_aliases_file) do
      get_path_aliases_helper(path_aliases_raw, st0)
    end
  end
end

# This is just like get_path_aliases, but expects the raw file contents instead
# of the filename (path) to read out.
def_lua_func get_path_aliases_fake([path_aliases_raw], st0) do
  get_path_aliases_helper(path_aliases_raw, st0)
end

def get_path_aliases_helper(path_aliases_raw, st0) do
  req = %MelbyRenderer.ParsePathAliasesRequest{}
  req = Map.put(req, :path_aliases_raw, path_aliases_raw)

  # Call out to melbyr over gRPC.
  addr = get_melbyr_addr()
  with {:ok, channel} <- GRPC.Stub.connect(addr),
       {:ok, reply} <- MelbyRenderer.Renderer.Stub.parse_path_aliases(
         channel, req, timeout: 200) do
    GRPC.Stub.disconnect(channel)
    if reply.status == :PARSE_STATUS_ERROR do
      Logger.warning("parse failed: #{inspect(reply.error)}")
    end
    {:ok, reply.path_aliases, st0}
  else
    err -> raise "failed to successfully call melbyr: #{inspect(err)}"
  end
end
#+end_src

*** Colorized Git SHA

#+name: __NREF__melbyd_luasdk_get_colorized_sha
#+begin_src elixir
def_lua_func get_colorized_sha([sha, sha_length, pad_left, pad_right], st0) do
  render_options = get_render_options(st0)

  req = %MelbyRenderer.ColorizedGitShaRequest{}
  req = Map.put(req, :sha, sha)
  req = Map.put(req, :sha_length, sha_length)
  req = Map.put(req, :pad_left, pad_left)
  req = Map.put(req, :pad_right, pad_right)
  req = Map.put(req, :render_options, render_options)

  Logger.debug("elixir req was: #{inspect(req)}")

  addr = get_melbyr_addr()
  with {:ok, channel} <- GRPC.Stub.connect(addr),
       {:ok, reply} <- channel |> MelbyRenderer.Renderer.Stub.get_colorized_git_sha(req, timeout: 200) do
    GRPC.Stub.disconnect(channel)
    {:ok, reply.sha_colorized, st0}
  end
end
#+end_src

*** Time

FIXME: Use Timex library here also to avoid making the user use the stupid
"America/Los_Angeles" timezone and instead the shorter names that the "%Z"
strftime uses, because then the user doesn't hae to use =timedatectl= as well.

Construct the time string from the time format string, and optional time zone
and UNIX seconds. We take in these optional parameters so that the test code can
inject them (otherwise the tests will break as the values tested will no longer
be constant).

#+name: __NREF__melbyd_luasdk_get_time
#+begin_src elixir
def_lua_func get_time([format, unix_seconds, time_zone], st0) do
  # Use UTC by default.
  tz =
    cond do
      time_zone == "LOCAL" -> Timex.Timezone.local().full_name
      timezone_ok(time_zone) -> time_zone
      true -> "Etc/UTC"
    end

  # Use the current time if unix_seconds is not provided.
  sec =
    if unix_seconds do
      if is_binary(unix_seconds) do
        String.to_integer(unix_seconds)
      else
        unix_seconds
      end
    else
      with {:ok, t} <- DateTime.now(tz),
           do: DateTime.to_unix(t)
    end

  # Format the current time with the given format string.
  t =
    DateTime.from_unix!(sec)
    |> DateTime.shift_zone!(tz)

  {:ok, Calendar.strftime(t, format), st0}
end

def_lua_func get_unix_seconds(_, st0) do
  with {:ok, t} <- DateTime.now("Etc/UTC"),
       do: {:ok, DateTime.to_unix(t), st0}
end

def timezone_ok(tz) do
  case DateTime.now(tz) do
    {:ok, _} ->
      true

    _ ->
      Logger.warning("unrecognized timezone: '#{tz}'")
      false
  end
end
#+end_src

*** Export to shell script

FIXME: This should be another NIF because the logic here is purely functional
(independent of the Lua VM state).

The use of =mapfile= is from https://stackoverflow.com/a/47862096/437583. We use
it instead of running =cat= because it avoids spawning a separate OS process.

#+name: __NREF__melbyd_luasdk_to_shell_script
#+begin_src elixir
def_lua_func to_shell_script([exports_ref], st0) do
  exports_list = Luerl.decode(st0, exports_ref) |> Melbyd.LuerlUtil.array_to_native_list()
  exports = exports_list |> Enum.map(&Melbyd.LuerlUtil.table_to_native_map/1)

  Logger.debug("exports is #{inspect(exports)}")

  script =
    exports
    |> Enum.reduce("", fn export_map, acc ->
      acc <> export_shell_var(export_map)
    end)

  Logger.debug("script is #{inspect(script, limit: :infinity, binaries: :as_strings)}")

  {:ok, script, st0}
end

def export_shell_var(%{"name" => name, "val" => val, "type" => type}) do
  case type do
    "array" ->
      ret = """
      declare -a #{name}
      #{name}=(
      """

      ret =
        Melbyd.LuerlUtil.array_to_native_list(val)
        |> Enum.reduce(ret, fn item, acc -> acc <> "#{inspect(item)}" end)

      ret <> "\n)\n"

    _ ->
      # FIXME: Technically this is broken if "v" has a string "END_HEREDOC" on
      # its own line. There are ways around this but for now we don't care.
      #
      # It's doubly broken because "k" could have an invalid non-keyword
      # character in it. But again we don't care for now.
      """
      #{name}=$(cat << 'END_HEREDOC'
      #{val}
      END_HEREDOC
      )
      """
  end
end
#+end_src

*** Expected functions in the Lua file for SRS

We expect the Lua file to include a =Config.view()= function that will be used
to generate all the data to read and present as the final /view/ back to the
client. The Lua configuration is free to call into Elixir with the provided
functions in the =Melbyd.LuaSdk= module (exposed through the =melbyd= Lua table).

**** Functions for instantiating a SRS GenServer

#+name: __NREF__melbyd_luasdk_srs
#+begin_src elixir
def_lua_func read_standard_resource([resource_ref, resource_opts_ref], st0) do
  resource = resource_ref_to_native_map(resource_ref, st0)
  resource_opts = Luerl.decode(st0, resource_opts_ref) |> Melbyd.LuerlUtil.table_to_native_map()

  resource_opts = Map.put(resource_opts, "fake", false)

  # Now we just have to pass in this data into a SRS initializer function. This
  # initializer function is the Melbyd.StandardResource.get_state() function,
  # which does the work of calling out to the DynamicSupervisor if necessary
  # before retrieving the state. The interesting thing is that the
  # Melbyd.StandardResource module itself calls into the Lua config to determine
  # what kind of business logic it needs to run, especially for the control
  # loop.
  res = Melbyd.StandardResource.read(resource, resource_opts)
  {:ok, res, st0}
end

def resource_ref_to_native_map(resource_ref, st0) do
  resource_luerl = Luerl.decode(st0, resource_ref)
  resource = Melbyd.LuerlUtil.table_to_native_map(resource_luerl)
  parser = Melbyd.LuerlUtil.table_to_native_map(resource["parser"])
  fake = Melbyd.LuerlUtil.table_to_native_map(resource["fake"])
  resource = Map.put(resource, "parser", parser)
  Map.put(resource, "fake", fake)
end
#+end_src

***** Fake

This is like =read_standard_resource=, but instead of reading things the regular
way, we inject a special "fake" key in the resource_opts so that the reader
knows that it is fake and understands it should execute the fake readers and
also the resource_id_func instead of the resource_id_command. The good thing is
that all of these bits should already be defined in the resource already by the
user.

FIXME: We must put all SRS and SPS resources in a separate =namespace= so as to
not collide with actual production resources. E.g., we don't want to create an
SRS or SPS GenServer instance whose =id= would collide with one for production.
We need to create a unique token for a validation request and use that as part
of the resource IDs so that multiple validation requests do not walk on each
other. Hmm, actually, what we need is a concurrent non-blocking cache. We need
to make it so that we hash the incoming code's contents to generate a
deterministic key (md5sum), then use this key as the validation result, and
cache this result. If there are any other requests coming into melbyd for the
same config, they also will get hashed to the same key, and must wait for the
first request's already-in-progress validation to succeed. We can use Cachex and
its so-called "fallbacks" to get this concurrent non-blocking cache behavior.

#+name: __NREF__melbyd_luasdk_srs_fake
#+begin_src elixir
def_lua_func read_standard_resource_fake([resource_ref, resource_opts_ref], st0) do
  resource = resource_ref_to_native_map(resource_ref, st0)
  resource_opts = Luerl.decode(st0, resource_opts_ref) |> Melbyd.LuerlUtil.table_to_native_map()

  # Stamp this as being fake for all downstream code.
  resource_opts = Map.put(resource_opts, "fake", true)

  # Save vm_fingerprint so that it's accessible easily from the Elixir side.
  {vm_fingerprint, _} = Luerl.get_table1(st0, ["melbyd", "vm_fingerprint"])
  resource_opts = Map.put(resource_opts, "vm_fingerprint", vm_fingerprint)

  res = Melbyd.StandardResource.read(resource, resource_opts)
  {:ok, res, st0}
end
#+end_src

**** Functions to help with string handling

SRS lets users write UNIX commands that will be executed and parsed back.
Oftentimes, users will want to reach for the same facilities, such as string
whitespace trimming, to make parsing in Lua easier. We provide such
functionality here. This way users don't have to write at a lower level too much
in their Lua configuration.

***** =get_lines_trimmed_nonempty=

Convert an arbitrary string into an array of strings, splitting on newlines and
trimming each line. Discards empty lines.

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func get_lines_trimmed_nonempty([s], st0) do
  lines =
    s
    |> String.split(@newlines)
    |> Enum.take_while(fn x -> String.trim(x) |> String.length() > 0 end)

  {:ok, lines, st0}
end
#+end_src

***** =get_trimmed=

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func get_trimmed([s], st0) do
  {:ok, String.trim(s), st0}
end
#+end_src

***** =split=

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func split([s, delim], st0) do
  {:ok, String.split(s, delim, trim: true), st0}
end
#+end_src

***** =get_group_or_default= and =get_int_group=

Given a regex pattern with a group, extract the given Nth group. If no such
group is found (or the pattern doesn't even match), return the default sring.

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func get_group_or_default([s, pat, nth, default], st0) do
  regex =
    try do
      Regex.compile!(pat)
    rescue
      e in Regex.CompileError ->
        Logger.error(got: e, from_pat: pat)
        nil
    end

  case regex do
    nil ->
      {:ok, default, st0}

    _ ->
      captures = Regex.run(regex, s)

      res =
        if captures == nil do
          default
        else
          case Enum.at(captures, nth) do
            nil -> default
            g -> g
          end
        end

      {:ok, res, st0}
  end
end

# Equivalent to get_group_or_default([s, pat, 1, 0], st0)
def_lua_func get_int_group([s, pat], st0) do
  {:ok, res, _st} = __internal__get_group_or_default([s, pat, 1, "0"], st0)
  {:ok, String.to_integer(res), st0}
end
#+end_src

***** =get_lines_matching_count=

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func get_lines_matching_count([s, pat], st0) do
  count = String.split(s, @newlines) |> Enum.count(fn x -> String.starts_with?(x, pat) end)
  {:ok, count, st0}
end
#+end_src

***** =get_kv_lines_as_map=

Given lines of the format ="key,value"=, return a hashmap of keys with their
values. Expects only 1 value for 1 key. If there is more than 1 instance of the
delimiter on the line, this is an error.

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func get_kv_lines_as_map([s], st0) do
  {:ok, lines, _st} = __internal__get_lines_trimmed_nonempty([s], st0)

  kvs =
    Enum.map(lines, fn line ->
      [k, v] = String.split(line, ",")
      {k, v}
    end)

  {:ok, Map.new(kvs), st0}
end
#+end_src

***** =get_columnar_fields_zipped=

Given a line like ="value1<WHITESPACE>value2"=, and a list of keys, return a map
with the keys and their respective values. The number of keys and values must
match.

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func get_columnar_fields_zipped([s, keys_ref], st0) do
  keys = Luerl.decode(st0, keys_ref) |> Melbyd.LuerlUtil.array_to_native_list()
  trimmed_line = String.trim(s)
  vals = String.split(trimmed_line)
  kvs = Enum.zip(keys, vals)

  {:ok, Map.new(kvs), st0}
end
#+end_src

***** =cast_values=

Convert some fields in a Lua table into a value other than a string. Here, =t=
is the table of key/values we want to cast, and =keytypes= is a table of
key/types.

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func cast_values([t_ref, keytypes_ref], st0) do
  t = Luerl.decode(st0, t_ref) |> Melbyd.LuerlUtil.table_to_native_map()
  keytypes = Luerl.decode(st0, keytypes_ref) |> Melbyd.LuerlUtil.table_to_native_map()

  ret =
    Enum.reduce(t, %{}, fn {key, val}, acc ->
      if Map.has_key?(keytypes, key) do
        case keytypes[key] do
          "float" ->
            Map.put(acc, key, to_number(val, key))

          "int" ->
            Map.put(acc, key, Kernel.trunc(to_number(val, key)))

          "bool" ->
            Map.put(acc, key, to_bool(val))

          # If we can't figure out the type, log an error and use the uncasted value.
          type ->
            Logger.error("key #{inspect(key)}: unrecognized type #{inspect(type)}")
            Map.put(acc, key, val)
        end
      else
        Map.put(acc, key, val)
      end
    end)

  {:ok, ret, st0}
end

def to_number(s, field) when is_binary(s) do
  case Float.parse(s) do
    :error ->
      Logger.error("field #{inspect(field)}: could not convert #{inspect(s)} to float; defaulting to 0")
      0

    {f, _rem} ->
      f
    _ -> 0
  end
end

def to_number(n, field) when is_number(n) do
  Logger.debug("field #{inspect(field)}: #{n} is already a number; using it as-is")
  n
end

def to_number(x, field) do
  Logger.error("field #{inspect(field)}: #{x} is not a number; defaulting to 0")
  0
end

def to_bool(s) do
  case s do
    str
    when str in ["", "n", "N", "no", "No", "NO", "nil", "Nil", "NIL", "false", "False", "FALSE"] ->
      false

    _ ->
      true
  end
end
#+end_src

***** =get_relative_age=

Given a UNIX timestamp, return a relative age. E.g., "5s" for a time stamp 5 seconds in the past, ro "5M" for 5 months ago.

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func get_relative_age([unix_seconds_float], st0) do
  Logger.debug("unix_seconds: #{unix_seconds_float}")
  unix_seconds = Kernel.trunc(unix_seconds_float)
  t = Timex.from_unix(unix_seconds)
  {:ok, s} = Timex.format(t, "{relative}", :relative)

  {:ok, s, st0}
end
#+end_src

***** =get_relative_age_short=

This is like =get_relative_age=, but much shorter. It's also not localized.
Below is a table of age ranges and how we display it, where *N* represents a
number. We treat 1 month to be 4 weeks long.

| Age                                                                   | Output | Truncation                                      |
| 0 - 59 seconds                                                        | Ns     |                                                 |
| 1 minute - 59 minutes and 59 seconds                                  | Nm     | Seconds                                         |
| 1 - 47 hours 59 minutes and 59 seconds                                | Nh     | Minutes and seconds                             |
| 2 days - 6 days, hours 59 minutes and 59 seconds                      | Nd     | Hours, minutes and seconds                      |
| 1 weeks - 3 weeks, 6 days, hours 59 minutes and 59 seconds            | Nw     | Days, hours, minutes and seconds                |
| 1 month - 11 months, 3 weeks, 6 days, hours 59 minutes and 59 seconds | NM     | Weeks, days, hours, minutes and seconds         |
| 1 year and older                                                      | NY     | Months, weeks, days, hours, minutes and seconds |
#+TBLFM:

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func get_relative_age_short([unix_seconds_float], st0) do
  Logger.debug("unix_seconds: #{unix_seconds_float}")
  t1 = Kernel.trunc(unix_seconds_float)
  # t1 = Timex.from_unix(unix_seconds)
  t2 = Timex.now() |> Timex.to_unix()

  age_seconds = t2 - t1

  age = Timex.Duration.from_seconds(age_seconds)

  s =
    cond do
      Timex.Duration.to_minutes(age) < 1 ->
        "#{age_seconds}s"

      Timex.Duration.to_hours(age) < 1 ->
        minutes = Kernel.trunc(Timex.Duration.to_minutes(age))
        "#{minutes}m"

      Timex.Duration.to_hours(age) < 48 ->
        hours = Kernel.trunc(Timex.Duration.to_hours(age))
        "#{hours}h"

      Timex.Duration.to_days(age) < 14 ->
        days = Kernel.trunc(Timex.Duration.to_days(age))
        "#{days}d"

      Timex.Duration.to_days(age) < 30 ->
        weeks = Kernel.trunc(Timex.Duration.to_days(age) / 7)
        "#{weeks}w"

      Timex.Duration.to_days(age) < 365 ->
        months = Kernel.trunc(Timex.Duration.to_days(age) / 30)
        "#{months}M"

      true ->
        years = Kernel.trunc(Timex.Duration.to_days(age) / 365)
        "#{years}Y"
    end

  {:ok, s, st0}
end
#+end_src

***** =get_truncated_personal_moniker=

Given a first and last name, shorten it to the first name's inital and the last
name, truncating the last name as necessary.

#+header: :noweb-ref __NREF__melbyd_luasdk_srs_helpers
#+begin_src elixir
def_lua_func get_truncated_personal_moniker([first_last_name, max], st0) do
  Logger.debug("first_last_name: #{first_last_name}")

  s =
    case String.split(first_last_name) do
      [] ->
        "?"

      [name] ->
        String.slice(name, 0..(max - 1))

      [first_name, last_name] ->
        String.first(first_name) <> String.slice(last_name, 0..(max - 2))

      names ->
        String.first(List.first(names)) <> String.slice(List.last(names), 0..(max - 2))
    end

  {:ok, s, st0}
end
#+end_src

*** Messaging

#+header: :noweb-ref __NREF__melbyd_luasdk_pubsub
#+begin_src elixir
def_lua_func broadcast([topic, message_ref], st0) do
  message = Luerl.decode(st0, message_ref) |> Melbyd.LuerlUtil.table_to_native_map_atomic_keys()

  payload = Melbyd.LuerlUtil.table_to_native_map_atomic_keys(message.payload)
  payload = Map.put(payload, :time, Calendar.strftime(Timex.local(), "%H:%M:%S"))
  message = Map.put(message, :payload, payload)

  Phoenix.PubSub.broadcast(Melbyd.PubSub, topic, message)

  # There is nothing to return back to Lua.
  {:ok, nil, st0}
end
#+end_src

**** Functions for instantiating an SPS GenServer

Here, =topics= is a list of topic names (strings) which we want to subscribe to.
The Lua config should know what topics to subscribe to.

#+name: __NREF__melbyd_luasdk_sps
#+begin_src elixir
def_lua_func get_shell_messages([shell_pid, resources_ref, env_vars_ref], st0) do
  resource_luerl_tables =
    Luerl.decode(st0, resources_ref) |> Melbyd.LuerlUtil.array_to_native_list()
  env_vars = Luerl.decode(st0, env_vars_ref) |> Melbyd.LuerlUtil.table_to_native_map()

  # Topic handlers is a map where the key is the resource type (e.g.,
  # "srs_Git"), and the handler is the Lua function named "should_keep_message"
  # for that resource.
  topic_handlers =
    resource_luerl_tables
    |> Enum.map(fn resource_luerl_table ->
      resource = Melbyd.LuerlUtil.table_to_native_map(resource_luerl_table)
      {"srs_" <> resource["type"], resource["should_keep_message"]}
    end)
    |> Map.new()

  messages = Melbyd.ShellProcess.get_messages(shell_pid, topic_handlers, env_vars)

  {:ok, messages, st0}
end
#+end_src

*** Other

#+name: __NREF__melbyd_luasdk_misc
#+begin_src elixir
def_lua_func log([msg], st0) do
  case msg do
    # If msg is not a primitive (e.g., a string), then decode it first. This way
    # we can handle Lua tables.
    x when is_tuple(x) ->
      y = Luerl.decode(st0, x)
      Logger.debug("(Melbyd Lua SDK debug (string)): #{inspect(y, limit: :infinity, binaries: :as_strings)}")
      Logger.debug("(Melbyd Lua SDK debug (binary)): #{inspect(y, limit: :infinity, binaries: :as_binaries)}")
    x ->
      Logger.debug("(Melbyd Lua SDK debug (string)): #{inspect(x, limit: :infinity, binaries: :as_strings)}")
      Logger.debug("(Melbyd Lua SDK debug (binary)): #{inspect(x, limit: :infinity, binaries: :as_binaries)}")
  end
  {:ok, nil, st0}
end
#+end_src

** Boilerplate

#+name: __NREF__melbyd_luasdkhelper
#+begin_src elixir
defmodule Melbyd.LuaSdkLoadable do
  require Logger

  # This prevents programmer errors where we no longer autogenerate an install/1
  # function. This will probably never happen, but because we don't have types
  # this is the best we can do.
  @callback install(Lua.t()) :: Lua.t()

  alias Melbyd.LuaSdkLoader, as: Loader

  defmacro __using__(_options \\ []) do
    quote do
      import unquote(__MODULE__)
      Module.register_attribute(__MODULE__, :loadable_functions, accumulate: true)
      @before_compile unquote(__MODULE__)
    end
  end

  # Maybe this macro should have been named "final_macro_expansion" or
  # something. But the point is that we run this after all other macros are
  # expanded, *just* before compilation to Erlang bytecode begins.
  defmacro __before_compile__(_env) do
    quote do

      # install/1 is called by Luerl's load_module() function. This is documented in https://github.com/rvirding/luerl/blob/bc655178dc8f59f29199fd7df77a7c314c0f2e02/src/NOTES#L115.
      def install(st) do
        table = Loader.load(@loadable_functions, __MODULE__)
        :luerl_heap.alloc_table(table, st)
      end
    end
  end

  # Note that all Elixir expressions, when quoted (converted into an AST), have
  # the form of {atom, context, arguments}.
  #
  # Here we pattern match the arguments so that we only process those function
  # declarations that want 2 arguments, because that's what Luerl requires of
  # us. (First argument is a  list of arguments passed in from the invocation of
  # this function from Lua, and the second argument is the Lua VM state.)
  #
  # We define 2 functions for every def_lua_func macro. The first is a private
  # function that actually captures the business logic. The second is a wrapper
  # that makes sure that the function behaves as a proper Luerl-compatible
  # function, in that it always returns things through the Loader.to_luerl/1
  # helper function. We basically use this to force all functions to behave
  # properly.
  #
  # "dlf_block" means "def_lua_func block".
  defmacro def_lua_func({f_name, f_context, [_args_from_lua, _st] = f_args} = _elixir_expression,
             do: dlf_block
           ) do
    # If a user created a function named "foo", then create another Elixir
    # function named as "__handle_lua_call__foo".
    prefixed_f_name = String.to_atom("__handle_lua_call__" <> Atom.to_string(f_name))
    prefixed_f_name_internal = String.to_atom("__internal__" <> Atom.to_string(f_name))

    quote do
      # Register this function call (make a note of it) into the
      # @loadable_functions attribute.
      @loadable_functions unquote(prefixed_f_name)

      # This is the wrapper function that is publicly visible to Luerl. It runs
      # the business logic and makes sure to wrap the return values in a form
      # that Luerl expects by piping to Loader.to_luerl/1.
      def unquote(prefixed_f_name)(args_list_from_lua, lua_state) do
        unquote(prefixed_f_name_internal)(args_list_from_lua, lua_state)
          |> Loader.to_luerl
      end

      # This is the private function that actually houses the business logic.
      defp unquote({prefixed_f_name_internal, f_context, f_args}) do
        # Define the function body (written by the user in the "do ... end"
        # part) as-is.
        unquote(dlf_block)
      end
    end
  end
end

# The point of this module is so that we can minimize our use of macros. This
# way, we minimize the amount of code we generate dynamically to only generate
# the bare minimum to get things working.
defmodule Melbyd.LuaSdkLoader do

  def load(elixir_funcs, module) do
    Enum.map(elixir_funcs, fn elixir_func ->
      # From the Lua side, we can call an Elixir function by its "short" name,
      # without the leading "__handle_lua_call__" prefix.
      lua_func_name =
        String.replace_prefix(Atom.to_string(elixir_func), "__handle_lua_call__", "")

      # The arity is fixed at 2, because (FIXME: add link).
      elixir_func_reference = Function.capture(module, elixir_func, 2)
      {lua_func_name, {:erl_func, elixir_func_reference}}
    end)
  end

  # Helper function for returning things back to Luerl (Lua VM) from an autoloaded Elixir
  # module.
  #
  # Through trial and error, it appears that the return value must be a tuple
  # where the first element is what's returned to Lua and the second element is
  # the new state of the Lua VM.
  #
  # The first element itself has to be a list of 2 elements, of the form
  # [lua_return_value, error]. If we don't do this we get a strange error from
  # Elixir. The error, if not nil, must be a string.
  #
  # For consistency with idiomatic Elixir, we make callers use the familiar
  # "{:ok, foo}" and "{:error, message}" patterns and translate them here to
  # make luerl happy.
  def to_luerl(val) do
    case val do
      {:ok, result, st} ->
        # We need to encode results before the Lua functions can use them.
        {result_encoded, st1} = Luerl.encode(st, result)
        {[result_encoded, nil], st1}
      {:error, msg, st} -> {[nil, msg], st}
      got -> raise "got #{got}, expected {:ok, result, st} or {:error, msg, st}"
    end
  end
end
#+end_src

** Luerl util

#+name: __NREF__melbyd_luerl_util
#+begin_src elixir
defmodule Melbyd.LuerlUtil do
  __NREF__melbyd_luerl_util_table_lookup
  __NREF__melbyd_luerl_util_array_to_native_list
  __NREF__melbyd_luerl_util_table_to_native_map
  __NREF__melbyd_luerl_util_table_to_native_map_atomic_keys
end
#+end_src

*** Reading from Lua tables returned by Luerl

Luerl returns Lua tables to Elixir as a list of tuples, where the first element
is the index and the second element is the value. This scheme is used to
represent both Lua arrays (where the keys are positive integers starting with
=1=) and tables (where the keys can be arbitrary string values).

What we want to do is to be able to read deeply nested values from such a table,
by providing a list of keys to look up. For example, for a native Elixir map
with nested maps, the syntax would look like this:

#+begin_src elixir
foo_map["a"]["b"]["c"]
#+end_src

and we want to do something similar to a table returned by Luerl. Something like this:

#+begin_src elixir
lookup(foo_table, ["a", "b", "c"])
#+end_src

The key (no pun intended) is to do a linear search of all tuples to find the
right tuple, and to repeat this search on the resulting value as many times as
necessary.

#+name: __NREF__melbyd_luerl_util_table_lookup
#+begin_src elixir
def table_lookup(_t, []) do
  raise ArgumentError, message: "lookup_keys cannot be empty"
end

def table_lookup(t, lookup_keys) do
  Enum.reduce(lookup_keys, t, fn lookup_key, val_so_far ->
    if not Kernel.is_list(val_so_far) do
      raise ArgumentError, message: "val_so_far '#{inspect(val_so_far)}' is not a list"
    end

    Enum.map(val_so_far, &verify_table_tuple/1)

    found = Enum.find(val_so_far, fn {t_key, _t_val} -> t_key == lookup_key end)

    if found == nil do
      raise ArgumentError, message: "lookup_key '#{lookup_key}' not found"
    else
      {_t_key, t_val} = found
      t_val
    end
  end)
end

def verify_table_tuple({k, _v}) when is_binary(k) do
  :ok
end

def verify_table_tuple(x) do
  raise ArgumentError, message: "element '#{inspect(x)}' is not a well-formed tuple"
end
#+end_src

*** Array to native list

Luerl returns arrays as a list of tuples, with each element being of the form
={k, v}= where =k= is the positive integer index and =v= is some other arbitrary
value.

Here we convert such a list of tuples into a plain list with all of the indices
removed. We expect the indices to be well-formed, meaning that the indices are
contiguous, ascending, and start from =1=.

#+name: __NREF__melbyd_luerl_util_array_to_native_list
#+begin_src elixir
def array_to_native_list(a) do
  Enum.map(a, &verify_array_tuple/1)

  {_, native_list} =
    Enum.reduce(a, {0, []}, fn {k, v}, {i, native_list} ->
      if k == i + 1 do
        {k, [v | native_list]}
      else
        raise ArgumentError, message: "expected index #{i + 1} for element '#{inspect({k, v})}'"
      end
    end)

  Enum.reverse(native_list)
end

def verify_array_tuple({k, _v}) when is_integer(k) do
  :ok
end

def verify_array_tuple(x) do
  raise ArgumentError, message: "element '#{inspect(x)}' is not a well-formed tuple"
end
#+end_src

*** Table to native map

#+name: __NREF__melbyd_luerl_util_table_to_native_map
#+begin_src elixir
def table_to_native_map(t) do
  Enum.map(t, &verify_table_tuple/1)
  Map.new(t)
end
#+end_src

Below is a specialized version which also converts all keys to atoms. This
should only be used for cases where the keys are known to be some subset, as
atoms are never garbage-collected.

#+name: __NREF__melbyd_luerl_util_table_to_native_map_atomic_keys
#+begin_src elixir
def table_to_native_map_atomic_keys(t) do
  Enum.map(t, &verify_table_tuple/1)
  Enum.map(t, fn {k, v} -> {String.to_atom(k), v} end) |> Map.new()
end
#+end_src

*** Lua tables to Elixir maps

The reason why we don't convert from a Lua table to an Elixir Map or List
(recursively) is because we are not sure how to handle the empty table ={}= in
Lua --- it can represent either an empty Map or List. See
https://github.com/rvirding/luerl/wiki/0.7-Data-representation.

** Tests

We have a Lua smoke test to check that Lua/Elixir interop is working. This tests
the sample Lua configuration to ensure that it is a fully working example.

#+begin_src elixir :tangle daemon/config/test.exs
import Config

# Log everything during tests. We want to see all logs in case a test fails.
config :logger,
  level: :debug
#+end_src

#+begin_src elixir :tangle daemon/test/melbyd_test.exs
defmodule MelbydTest do
  use ExUnit.Case
  require Logger
  require WaitForIt

  setup_all do
    IO.puts("resetting fake_kube_config")
    content = "current-context=one\ncurrent-namespace=default\n"
    {:ok, mix_root} = File.cwd()
    path = mix_root <> "/test/fake_kube_config"
    File.write(path, content)
    :ok
  end

  # Generate a unique-looking 7-digit shell pid based on the module and test
  # name. This is important because each test must use a unique shell pid. The
  # alternative to using this helper function is to maually assign a unique
  # shell pid for each test case, which is error-prone.
  defp get_unique_shell_pid(module_name_atom, test_name_atom) do
    module_test_str = Atom.to_string(module_name_atom) <> Atom.to_string(test_name_atom)
    pid_length = 7

    :crypto.hash(:md5, module_test_str)
    |> :binary.decode_unsigned()
    |> Integer.to_string()
    |> String.graphemes()
    |> Enum.drop_while(fn c -> c == "0" end)
    |> Enum.take(pid_length)
    |> Enum.join()
    |> String.pad_trailing(pid_length, "0")
  end

  defp run_git_script(path, shell_script) do
    preamble = """
    set -euo pipefail
    clock_time="Thu, 07 Apr 2005 15:13:13 -0700"
    export GIT_AUTHOR_DATE="${clock_time}"
    export GIT_AUTHOR_NAME=a
    export GIT_AUTHOR_EMAIL=a@b.edu
    export GIT_COMMITTER_DATE="${clock_time}"
    export GIT_COMMITTER_NAME=d
    export GIT_COMMITTER_EMAIL=e@f.edu
    export GIT_CONFIG_GLOBAL=1
    export GIT_CONFIG_NOSYSTEM=1
    """

    # Run shell script at the given path. The stderr_to_stdout is so that we
    # capture all results into the "output" variable, to be sent to the
    # Logger.debug. Otherwise, the stderr output is not captured and always
    # displayed, going against the intent of `import ExUnit.CaptureLog` above.
    {output, ret} =
      System.cmd("bash", ["-c", preamble <> shell_script], cd: path, stderr_to_stdout: true)

    Logger.debug("got bash output: #{inspect(output)}")

    assert ret == 0
  end

  defp mk_tmp_dir(prefix) do
    Temp.track!()

    {:ok, dir_path} = Temp.mkdir(prefix)
    # On Darwin, /tmp is symlinked to /private/tmp. Temp.mkdir() (and even
    # Elixir's System.temp_dir()) uses "/tmp" as the temp directory. However,
    # this doesn't stop other Elixir libraries or even our own code (shelling
    # out to external commands) from using the non-symlinked version
    # "/private/tmp". So, make ourselves also use the dereferenced
    # (non-symlinked) path for consistency.
    Logger.warning("dir_path #{dir_path}")
    if :os.type() == {:unix, :darwin} do
      "/private" <> dir_path
    else
      dir_path
    end
  end

  # Initialize state (AGENT)
  defp init_lua_reader() do
    Agent.start_link(fn -> "" end)
  end

  # Read state (CONSUMER)
  defp get_lua_reader_state(pid) do
    Agent.get(pid, & &1)
  end

  # Update state (PRODUCER)
  defp update_lua_reader_state(pid, shell_pid, lua_script, env_vars, ansi_escapes_allowed) do
    case Melbyd.LuaInterop.run(lua_script, ["Config", "view"], [env_vars, shell_pid]) do
      {:ok, [got]} ->
        Agent.update(pid, fn _ ->
          if ansi_escapes_allowed do
            got
          else
            strip_ansi(got)
          end
        end)

      x ->
        Logger.error("failed to run lua script: #{x}")
    end
  end

  defp expect(want, pid, shell_pid, lua_script, env_vars, ansi_escapes_allowed) do
    update_lua_reader_state(pid, shell_pid, lua_script, env_vars, ansi_escapes_allowed)
    get_lua_reader_state(pid) =~ want
  end

  # FIXME: Change argument order to match assert_output_substrings.
  defp assert_output_string(want, shell_pid, lua_script, env_vars, ansi_escapes_allowed) do
    {:ok, pid} = init_lua_reader()

    # Wait up to 5 seconds (5 poll events) to see if we can get some output that
    # has our =want= substring in it.
    WaitForIt.wait(
      expect(want, pid, shell_pid, lua_script, env_vars, ansi_escapes_allowed),
      frequency: 1000,
      timeout: 5_000
    )

    got = get_lua_reader_state(pid)
    Agent.stop(pid)
    assert got =~ want
  end

  defp strip_ansi(s) do
    # This is a terrible regex, but performs adequately because our ANSI codes
    # are well-formed.
    Regex.replace(~r/\e\[([0-9;])*m/, s, "")
  end

  defp assert_output_substrings(
         want_substrs,
         shell_pid,
         lua_script,
         env_vars,
         ansi_escapes_allowed
       ) do
    {:ok, pid} = init_lua_reader()

    # Wait for the last substring to appear.
    WaitForIt.wait(
      expect(List.last(want_substrs), pid, shell_pid, lua_script, env_vars, ansi_escapes_allowed),
      frequency: 1000,
      timeout: 5_000
    )
    # Alternate: wait for all substrings to appear. But actually, this is broken because we run the lua script too many times (once for each substring); so then our backend will purge any already-broadcasted shell message. The right approach is to wait up to 5 seconds, and during that time do fetches 1x per second, and for each fetch we should check how many of the substrings have matched, and NOT re-check those already-matched substrings in the next iteration. That is, we should match as much as possible each time we run the lua script and fetch (this way different parts of the output string can match what we want overall).
    #WaitForIt.wait(
    #  Enum.map(
    #    want_substrs,
    #    fn s -> expect(s, pid, shell_pid, lua_script, env_vars, ansi_escapes_allowed)
    #    end) |> Enum.all?(),
    #  frequency: 1000,
    #  timeout: 5_000
    #)

    # Run the Lua script to simulate invoking melbyc.
    got = get_lua_reader_state(pid)
    Agent.stop(pid)

    # Check every substring, not just the last one.
    # FIXME: Make this stricter by consuming the input in order (the substrings
    # must be found in order).
    Enum.each(want_substrs, fn substr ->
      assert String.contains?(got, substr)
    end)
  end

  # This tag lets us do "mix test --only basic" to only run this test.
  @tag basic: true
  test "basic smoke test (no git repo)", %{test: test_name} do
    shell_pid = get_unique_shell_pid(__MODULE__, test_name)

    {:ok, mix_root} = File.cwd()
    lua_script = mix_root <> "/test/sample/melby.lua"

    env_vars = %{
      KUBECONFIG: mix_root <> "/test/fake_kube_config",
      HOME: mix_root,
      # This path doesn't exist, but it doesn't really matter for purposes of
      # testing the path shortening logic.
      PWD: mix_root <> "/go/src/k8s.io/kubernetes",
      USER: "foo",
      HOST: "laptop",
      MELBY_UNIX_SECONDS: "1234567890",
      MELBY_TIME_ZONE: "America/Los_Angeles",
      MELBY_ZSH_KEYMAP_INDICATOR: "N",
      MELBY_PATH_ALIASES_FILE: mix_root <> "/test/sample/path-aliases",
      MELBY_DIR: mix_root <> "/test/sample"
    }

    assert_output_substrings(
      [
        "MELBY_PS1_LINE1",
        "\e[38;2;0;0;0;48;2;255;215;0;1m",
        "02-13  15:31:30 PST",
        "\e[38;2;0;0;0;48;2;255;192;203;1m",
        "02-13  23:31:30 UTC",
        "\e[0m\e[38;2;0;0;0;48;2;135;206;250;1m",
        "<N>",
        "foo@laptop",
        "\e[38;2;0;255;255;1m",
        "~kk",
        "MELBY_PS1_LINE2",
        "declare -a MELBY_SHELL_MESSAGES"
      ],
      shell_pid,
      lua_script,
      env_vars,
      true
    )
  end

  @tag ttl: true
  test "SRS ttl: exit when ttl reaches 0" do
    path_local = mk_tmp_dir("repo_local")

    run_git_script(path_local, """
    git init
    echo world > hello
    git add hello
    git commit -m 'initial import'
    """)

    {:ok, mix_root} = File.cwd()

    # Because the production code always sets the notify_on_exit_pid to nil (in
    # the normal codepath for users), we have to use a different code path. This
    # is essentially the body of the read_standard_resource Melbyd SDK function
    # we provide, but customized to not run Melbyd.StandardResource.read/2, but
    # to use our own logic to directly start the Melbyd.StandardResource
    # GenServer.
    {:ok, [resource_ref], st0} = Melbyd.LuaInterop.run_file(mix_root <> "/test/sample/Git.lua")

    resource = Melbyd.LuaSdk.resource_ref_to_native_map(resource_ref, st0)

    {:ok, _} =
      GenServer.start_link(Melbyd.StandardResource, %{
        id: {"Git", path_local},
        resource: resource,
        resource_opts: %{"PWD" => path_local, "fake" => false},
        ttl: 1,
        notify_on_exit_pid: self()
      })

    # FIXME: Move this 10_000 timeout to some global timeout (Application.get_env).
    assert_receive :shutting_down, 10_000
  end

  # We can't use :tmp_dir because we need multiple temporary directories.
  @tag git: true
  test "basic smoke test (with git repo)", %{test: test_name} do
    shell_pid = get_unique_shell_pid(__MODULE__, test_name)

    {:ok, mix_root} = File.cwd()

    # Create basic Git repo. We use a temporary folder for this.
    path_upstream = mk_tmp_dir("repo_upstream")

    run_git_script(path_upstream, """
    git init
    echo world > hello
    git add hello
    git commit -m 'initial import'
    """)

    path_local = mk_tmp_dir("repo_local")

    run_git_script(path_local, """
    cd /
    git clone --no-hardlinks #{path_upstream} #{path_local}
    """)

    env_vars = %{
      KUBECONFIG: mix_root <> "/test/fake_kube_config",
      HOME: "/home/foo",
      PWD: path_local,
      USER: "foo",
      HOST: "laptop",
      MELBY_UNIX_SECONDS: "1234567890",
      MELBY_TIME_ZONE: "America/Los_Angeles",
      MELBY_ZSH_KEYMAP_INDICATOR: "N",
      MELBY_PATH_ALIASES_FILE: mix_root <> "/test/sample/path-aliases",
      MELBY_DIR: mix_root <> "/test/sample"
    }

    path_local_short =
      Melbyd.Nifs.path_shorten(
        path_local,
        %{},
        %{"HOME" => "/home/foo"},
        30
      )

    lua_script = mix_root <> "/test/sample/melby.lua"

    # This initial response should not have Git information because it's too
    # quick (the Git watcher would have returned an initial empty loading
    # state). So check for the "[ Git... ]" string.
    assert_output_string("[ Git... ]", shell_pid, lua_script, env_vars, false)

    # After some time, the original "[ Git... ]" string should have disappeared
    # from the output by now, and we should have a final view like below.
    assert_output_substrings(
      [
        "MELBY_PS1_LINE1",
        "$(cat << 'END_HEREDOC'\n 02-13  15:31:30 PST   02-13  23:31:30 UTC   ",
        "<N>  foo@laptop #{path_local_short}\nEND_HEREDOC",
        "\n)\nMELBY_PS1_LINE2=$(cat << 'END_HEREDOC'\n[",
        " one:default 8T 5p 2r 0s 0f 1u]",
        " [ 3b83e1cd  master 19Y a]\nEND_HEREDOC\n)\ndeclare -a MELBY_SHELL_MESSAGES",
        "\nMELBY_SHELL_MESSAGES=(\n\n)\n",
      ],
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    # If we make some changes to it, we should see it reflected. We also only
    # test for changes to the prompt that we expect to see --- namely the Git
    # parts.
    run_git_script(path_local, """
    echo bye >> hello
    """)

    assert_output_substrings(
      ["[ 3b83e1cd  master 19Y a U1+1]"],
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    run_git_script(path_local, """
    git add hello
    """)

    assert_output_substrings(
      ["[ 3b83e1cd  master 19Y a S1+1]", "Staged size is now XS (4 bytes)."],
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    run_git_script(path_local, """
    git commit -m 'append bye'
    """)

    assert_output_string(
      "[ f679b84c  master 19Y a 1]",
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    run_git_script(path_upstream, """
    echo x >> x
    git add x
    git commit -m 'upstream change 1'
    """)

    run_git_script(path_local, """
    git fetch
    """)

    assert_output_string(
      "[ f679b84c  master 19Y a 1 1]",
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    run_git_script(path_local, """
    echo untracked > untracked
    """)

    assert_output_string(
      "[ f679b84c  master 19Y a 1 1 N1]",
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    run_git_script(path_local, """
    echo 0 >> hello
    git stash
    """)

    assert_output_string(
      "[ f679b84c  master 19Y a 1 1 N1 T1]",
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    run_git_script(path_local, """
    echo 2 > 2
    git add 2
    git commit -m 'local commit 2'
    echo x >> 2
    git update-index --assume-unchanged 2
    """)

    assert_output_string(
      "[ 2e4f8685  master 19Y a 2 1 N1 T1 A1]",
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    path_sm1 = mk_tmp_dir("sm1")

    # Add submodule, but don't initialize it.
    run_git_script(path_sm1, """
    git init
    echo sm1 > sm1
    git add sm1
    git commit -m 'initial import'
    """)

    # Due to Git CVE-2022-39253, we hae to pass in "-c
    # protocol.file.allow=always" in order to allow adding a submodule from
    # disk. See https://bugs.launchpad.net/ubuntu/+source/git/+bug/1993586.
    #
    # Also, because the absolute path on disk is unique in each run, it appears
    # that the resulting commit SHA will also be different on each run of this
    # test. To get around this, we don't check for the SHA any more.
    run_git_script(path_upstream, """
    git -c protocol.file.allow=always submodule add #{path_sm1} sm1
    git commit -m 'add submodule'
    """)

    run_git_script(path_local, """
    git update-index --no-assume-unchanged 2
    git checkout 2
    git pull --rebase
    """)

    assert_output_string(
      "master 19Y a 2 N1 T1 M{not_init=1}]",
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    path_sm2 = mk_tmp_dir("sm2")

    run_git_script(path_sm2, """
    git init
    echo sm2 > sm2
    git add sm2
    git commit -m 'initial import'
    """)

    run_git_script(path_upstream, """
    git -c protocol.file.allow=always submodule add #{path_sm2} sm2
    git commit -m 'add submodule sm2'
    """)

    run_git_script(path_local, """
    git pull --rebase
    git -c protocol.file.allow=always submodule update --init sm2
    """)

    run_git_script(path_sm2, """
    echo foo > foo
    git add foo
    git commit -m 'add foo'
    """)

    run_git_script(path_upstream, """
    cd sm2
    git pull
    cd ..
    git add --update
    git commit -m 'update submodule sm2'
    """)

    run_git_script(path_local, """
    git pull --rebase
    """)

    # The "C1+1-1" is because the local repo's sm2 is still checked out at an
    # older version, whereas upstream has moved on to a newer commit.
    assert_output_string(
      "master 19Y a 2 U1+1-1 N1 T1 M{not_init=1 need_sync=1}]",
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    run_git_script(path_sm2, """
    echo there > there
    git add there
    git commit -m 'add there'
    """)

    run_git_script(path_upstream, """
    cd sm2
    git pull
    cd ..
    git add sm2
    git commit -m 'use sm2 master'
    """)

    # If we try to merge two branches of the superproject together but they
    # reference different versions of a submodule, this should result in a
    # submodule merge conflict.
    run_git_script(path_local, """
    cd sm2
    git rm -f sm2
    echo hello > sm2
    git add sm2
    git commit -m 'changing sm2 locally'

    cd ..
    git add sm2
    git commit -m 'using local sm2 update'
    git fetch
    git merge origin/master || true
    """)

    assert_output_string(
      "master 19Y a 3 1 N1 T1 M{not_init=1 conflict=1}",
      shell_pid,
      lua_script,
      env_vars,
      false
    )
  end

  @tag k8s: true
  test "basic smoke test (with kubectl)", %{test: test_name} do
    shell_pid = get_unique_shell_pid(__MODULE__, test_name)

    {:ok, mix_root} = File.cwd()
    lua_script = mix_root <> "/test/sample/melby.lua"

    non_git_repo = mk_tmp_dir("non_git_repo")

    content = "current-context=one\ncurrent-namespace=default\n"
    kubeconfig = non_git_repo <> "/fake_kube_config"
    File.write(kubeconfig, content)

    env_vars = %{
      KUBECONFIG: kubeconfig,
      HOME: mix_root <> "/test/sample",
      PWD: non_git_repo,
      USER: "foo",
      HOST: "laptop",
      MELBY_UNIX_SECONDS: "1234567890",
      MELBY_TIME_ZONE: "America/Los_Angeles",
      MELBY_ZSH_KEYMAP_INDICATOR: "N",
      MELBY_PATH_ALIASES_FILE: mix_root <> "/test/sample/path-aliases",
      MELBY_DIR: mix_root <> "/test/sample"
    }

    assert_output_substrings(
      [
        "[ K8s... ]"
      ],
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    assert_output_substrings(
      [
        "one:default"
      ],
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    # Change config to point to "two:bar".
    content = "current-context=two\ncurrent-namespace=bar\n"
    File.write(kubeconfig, content)

    assert_output_substrings(
      [
        "Context changed from 'one' to 'two'.",
        "Namespace changed from 'default' to 'bar'."
      ],
      shell_pid,
      lua_script,
      env_vars,
      false
    )

    assert_output_substrings(
      [
        "two:bar"
      ],
      shell_pid,
      lua_script,
      env_vars,
      false
    )
  end
end
#+end_src
